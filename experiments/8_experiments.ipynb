{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6952d2-c7ab-466c-af6d-bb3f56e502cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c4f8f69-049b-4ebd-94bf-033477cd7138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe07074-9f64-417b-8d5b-0f4d19ef2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b1e06ef-cf71-46d5-8193-0dc965768b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af527a9d-39c4-4af0-b747-6d472aa5bfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5b2f7eb-7560-4c02-8d92-9cd456b6f613",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2fdacf-34cd-4110-8839-7ebe88cea32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(distr, start, end, step):\n",
    "    x = np.arange(start, end, step)\n",
    "    exp_f = np.exp(distr)\n",
    "    alpha = exp_f.sum() * 0.5\n",
    "    try:\n",
    "        median_low = x[exp_f.cumsum() <= alpha][-1]\n",
    "    except IndexError:\n",
    "        median_low = start\n",
    "    try:\n",
    "        median_high = x[::-1][exp_f[::-1].cumsum() < alpha][-1]\n",
    "    except IndexError:\n",
    "        median_high = end\n",
    "    median_avg = (median_low + median_high) / 2\n",
    "    return median_avg\n",
    "\n",
    "def get_thresholds_from_record(record, start=0, end=1, step=0.01):\n",
    "    thresholds = dict()\n",
    "    for claim in record:\n",
    "        thresholds[claim] = {'threshold': get_median(record[claim]['distributions'][-1], start, end, step)}\n",
    "    return thresholds\n",
    "\n",
    "def get_multi_pred(row, column, claims_dict, thresholds=None, black_list=None, min_length=1):\n",
    "    if thresholds is None:\n",
    "        thresholds = {t: {'threshold': 0.0} for t in claims_dict}\n",
    "    if black_list is None:\n",
    "        black_list = []\n",
    "    result = list()\n",
    "    if isinstance(row[column], list):\n",
    "        zsl_scores = {k:row[column][0][claims_dict[k]] for k in claims_dict}\n",
    "    else:\n",
    "        zsl_scores = {k:row[column][claims_dict[k]] for k in claims_dict}\n",
    "    for c in CLASSES:\n",
    "        sub_pred = {k: zsl_scores[k] for k in zsl_scores if k[:3] == c and not k in black_list}\n",
    "        if len([k for k in sub_pred if sub_pred[k] > thresholds[k]['threshold']]) >= min_length:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1f0e2-5c5c-4633-9a2f-de4f588dcb44",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61e4509-e9ff-4a36-8c17-17aab02b7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('./data/climate_change/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ca5f2d-8326-4f80-9b76-f77b1ab125c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['1_1', '1_2', '1_3', '1_4', '1_6', '1_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf08c169-9049-45c2-a178-8b9cc6e98615",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/climate_change/claims.json\") as file:\n",
    "    claims = json.load(file)\n",
    "\n",
    "claims_descr = claims[\"class_descr\"]\n",
    "del claims[\"class_descr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a4c2084-7231-456b-9cec-d290d9407027",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_claims = {claims[k]: k for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935d20d-51c9-4885-bd58-66349c47b653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "462a9842-ea08-45b1-a121-61d45ea72d1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 1: Changing the value of p for the Probabilistic Bisection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1655738-3ee1-4eb2-a61c-e9224e9c6a04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### p = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f27d6f4-2b67-484b-aa58-e63b037bf936",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/BART_0-6.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4912daae-19aa-477f-b26a-672ea9f970ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a71225-4559-41db-8efb-0991949f8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc680ac-3b23-4163-859b-40681165724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.68      0.64      0.66        36\n",
      "         1_2       0.46      0.92      0.61        12\n",
      "         1_3       0.61      0.77      0.68        48\n",
      "         1_4       0.76      0.67      0.71        70\n",
      "         1_6       0.83      0.62      0.71        24\n",
      "         1_7       0.10      0.65      0.17        34\n",
      "\n",
      "   micro avg       0.37      0.69      0.48       224\n",
      "   macro avg       0.57      0.71      0.59       224\n",
      "weighted avg       0.60      0.69      0.61       224\n",
      " samples avg       0.05      0.06      0.05       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd026b02-decd-4102-9d06-56127c0b01e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "554a1c56-8dcc-479e-992f-ee74b9956a41",
   "metadata": {
    "tags": []
   },
   "source": [
    "### p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58968e10-022f-4dd2-bd6f-79f60f52c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/BART_0-8.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6104fd-b3be-4fe3-9d82-7214a476e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975b77bb-4937-44d0-87c5-bea071f2fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17058a4d-18e3-4a29-a56f-7295bfed0869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.64      0.64      0.64        36\n",
      "         1_2       0.83      0.83      0.83        12\n",
      "         1_3       0.61      0.77      0.68        48\n",
      "         1_4       0.70      0.64      0.67        70\n",
      "         1_6       0.88      0.62      0.73        24\n",
      "         1_7       0.50      0.56      0.53        34\n",
      "\n",
      "   micro avg       0.65      0.67      0.66       224\n",
      "   macro avg       0.69      0.68      0.68       224\n",
      "weighted avg       0.67      0.67      0.66       224\n",
      " samples avg       0.05      0.05      0.05       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5cbdb-ce69-405a-9545-243afac53282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1dcbddf-afc2-449b-8c41-6874f7630046",
   "metadata": {
    "tags": []
   },
   "source": [
    "### p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb8fdd0d-d7a7-4101-92dc-9f899a8b89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/BART_0-9.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17b52cf3-80a2-40a2-89ec-720a07182bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f3ef085-f898-4d71-8dc5-a409f94c0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a35d507-6e06-42c5-ab0f-09f834a19d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.64      0.69      0.67        36\n",
      "         1_2       0.89      0.67      0.76        12\n",
      "         1_3       0.60      0.75      0.67        48\n",
      "         1_4       0.84      0.61      0.71        70\n",
      "         1_6       0.88      0.62      0.73        24\n",
      "         1_7       0.51      0.68      0.58        34\n",
      "\n",
      "   micro avg       0.68      0.67      0.67       224\n",
      "   macro avg       0.73      0.67      0.69       224\n",
      "weighted avg       0.71      0.67      0.68       224\n",
      " samples avg       0.05      0.05      0.05       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b3729-8e92-42bb-9ab2-9d200d57ca2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca7b90-55e4-4dc8-94e2-1347fc809d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e355d76-5f74-4f8d-8324-dc1eac53d5ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 2: Threshold-tuning on separate folds of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cc2c707-2924-4242-8011-263a3e8104e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/BART_FOLD_1.json') as file:\n",
    "    record_1 = json.load(file)\n",
    "\n",
    "with open('./data/bisection_records/BART_FOLD_2.json') as file:\n",
    "    record_2 = json.load(file)\n",
    "\n",
    "with open('./data/bisection_records/BART_FOLD_3.json') as file:\n",
    "    record_3 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32ff3526-d33d-4022-ad1d-6d4f19b23146",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop = 1\n",
    "step = 0.01\n",
    "x = np.arange(start, stop, step)\n",
    "\n",
    "def find_CI(distrib, low_mass=0.025, high_mass=0.975):\n",
    "    exp_f = np.exp(distrib)\n",
    "    alpha_low = exp_f.sum() * low_mass\n",
    "    alpha_high = exp_f.sum() * high_mass\n",
    "\n",
    "    try:\n",
    "        l_bound_low = x[exp_f.cumsum() <= alpha_low][-1]\n",
    "        l_low_weight = exp_f.cumsum()[int(l_bound_low * 100)]\n",
    "    except IndexError:\n",
    "        l_bound_low = start\n",
    "        l_low_weight = 0.0\n",
    "    try:\n",
    "        l_bound_high = x[::-1][exp_f[::-1].cumsum() <= alpha_high][-1]\n",
    "        l_high_weight = exp_f.cumsum()[int(l_bound_high * 100)]\n",
    "    except IndexError:\n",
    "        l_bound_high = stop\n",
    "        l_high_weight = 1.0\n",
    "    l_bound_avg = (l_bound_low + l_bound_high) / 2\n",
    "    if (l_bound_avg * 1000) % 10 != 0:\n",
    "        round_down = math.floor(int(l_bound_avg * 100))\n",
    "        round_up = math.ceil(int(l_bound_avg * 100))\n",
    "        l_weight = (exp_f.cumsum()[round_down] + exp_f.cumsum()[round_up]) / 2\n",
    "    else:\n",
    "        l_weight = exp_f.cumsum()[int(l_bound_avg * 100)]  \n",
    "        \n",
    "    try:\n",
    "        r_bound_low = x[exp_f.cumsum() <= alpha_high][-1]\n",
    "        r_low_weight = exp_f.cumsum()[int(r_bound_low * 100)]\n",
    "    except IndexError:\n",
    "        r_bound_low = start\n",
    "        r_low_weight = 0.0\n",
    "    try:\n",
    "        r_bound_high = x[::-1][exp_f[::-1].cumsum() <= alpha_low][-1]\n",
    "        r_high_weight = exp_f.cumsum()[int(r_bound_high * 100)]\n",
    "    except IndexError:\n",
    "        r_bound_high = stop\n",
    "        r_high_weight = 1.0\n",
    "    r_bound_avg = (r_bound_low + r_bound_high) / 2\n",
    "    if (r_bound_avg * 1000) % 10 != 0:\n",
    "        round_down = math.floor(int(r_bound_avg * 100))\n",
    "        round_up = math.ceil(int(r_bound_avg * 100))\n",
    "        r_weight = (exp_f.cumsum()[round_down] + exp_f.cumsum()[round_up]) / 2\n",
    "    else:\n",
    "        r_weight = exp_f.cumsum()[int(r_bound_avg * 100)]  \n",
    "\n",
    "    return l_bound_avg, r_bound_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "973f8eb9-783b-40ba-9d7b-076afc8f98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_low_1 = list()\n",
    "CI_low_2 = list()\n",
    "CI_low_3 = list()\n",
    "\n",
    "CI_high_1 = list()\n",
    "CI_high_2 = list()\n",
    "CI_high_3 = list()\n",
    "\n",
    "medians_1 = list()\n",
    "medians_2 = list()\n",
    "medians_3 = list()\n",
    "\n",
    "nb_annots_1 = list()\n",
    "nb_annots_2 = list()\n",
    "nb_annots_3 = list()\n",
    "nb_annots_whole = list()\n",
    "\n",
    "for idx, trait in enumerate(sorted(claims)):\n",
    "    \n",
    "    median_1 = sum(find_CI(record_1[trait]['distributions'][-1], low_mass=0.5, high_mass=0.5))/2\n",
    "    median_2 = sum(find_CI(record_2[trait]['distributions'][-1], low_mass=0.5, high_mass=0.5))/2\n",
    "    median_3 = sum(find_CI(record_3[trait]['distributions'][-1], low_mass=0.5, high_mass=0.5))/2\n",
    "    \n",
    "    l_bound_1, r_bound_1 = find_CI(record_1[trait]['distributions'][-1], low_mass=0.05, high_mass=0.95)\n",
    "    l_bound_2, r_bound_2 = find_CI(record_2[trait]['distributions'][-1], low_mass=0.05, high_mass=0.95)\n",
    "    l_bound_3, r_bound_3 = find_CI(record_3[trait]['distributions'][-1], low_mass=0.05, high_mass=0.95)\n",
    "    \n",
    "    CI_low_1.append(median_1 - l_bound_1)\n",
    "    CI_low_2.append(median_2 - l_bound_2)\n",
    "    CI_low_3.append(median_3 - l_bound_3)\n",
    "    \n",
    "    CI_high_1.append(r_bound_1 - median_1)\n",
    "    CI_high_2.append(r_bound_2 - median_2)\n",
    "    CI_high_3.append(r_bound_3 - median_3)\n",
    "\n",
    "    medians_1.append(median_1)\n",
    "    medians_2.append(median_2)\n",
    "    medians_3.append(median_3)\n",
    "    \n",
    "    nb_annots_1.append(len(record_1[trait]['annot']))\n",
    "    nb_annots_2.append(len(record_2[trait]['annot']))\n",
    "    nb_annots_3.append(len(record_3[trait]['annot']))\n",
    "    \n",
    "asymmetric_error_1 = [CI_low_1, CI_high_1]\n",
    "asymmetric_error_2 = [CI_low_2, CI_high_2]\n",
    "asymmetric_error_3 = [CI_low_3, CI_high_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70d669c3-efd0-4cbf-947b-08b821271a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "converged_1 = list()\n",
    "for t, low_b, high_b in zip(claims, asymmetric_error_1[0], asymmetric_error_1[1]):\n",
    "    if (high_b + low_b) < 0.2:\n",
    "        converged_1.append(t)\n",
    "        \n",
    "converged_2 = list()\n",
    "for t, low_b, high_b in zip(claims, asymmetric_error_2[0], asymmetric_error_2[1]):\n",
    "    if (high_b + low_b) < 0.2:\n",
    "        converged_2.append(t)\n",
    "        \n",
    "converged_3 = list()\n",
    "for t, low_b, high_b in zip(claims, asymmetric_error_3[0], asymmetric_error_3[1]):\n",
    "    if (high_b + low_b) < 0.2:\n",
    "        converged_3.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "875f251f-6021-4f76-bb46-083e4eb5e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_0_0 \t0.220\n",
      "1_1_0_1 \t0.110\n",
      "1_1_0_2 \t0.080\n",
      "1_1_1_0 \t0.110\n",
      "1_1_1_1 \t0.180\n",
      "1_1_2_0 \t0.130\n",
      "1_1_2_1 \t0.210\n",
      "1_1_3_0 \t0.170\n",
      "1_1_3_1 \t0.120\n",
      "1_1_4_0 \t0.170\n",
      "1_1_4_1 \t0.120\n",
      "1_2_0_0 \t0.170\n",
      "1_2_0_1 \t0.080\n",
      "1_3_0_0 \t0.110\n",
      "1_3_0_1 \t0.050 \tCONVERGED\n",
      "1_3_0_2 \t0.240\n",
      "1_3_0_3 \t0.250\n",
      "1_3_0_4 \t0.080 \tCONVERGED\n",
      "1_3_0_5 \t0.220\n",
      "1_4_0_0 \t0.070\n",
      "1_4_0_1 \t0.130\n",
      "1_6_0_0 \t0.160\n",
      "1_6_0_1 \t0.100 \tCONVERGED\n",
      "1_6_0_2 \t0.200\n",
      "1_6_0_3 \t0.050\n",
      "1_6_0_4 \t0.280\n",
      "1_7_0_0 \t0.120 \tCONVERGED\n",
      "1_7_0_1 \t0.010 \tCONVERGED\n",
      "1_7_0_2 \t0.130\n",
      "1_7_0_3 \t0.020\n"
     ]
    }
   ],
   "source": [
    "all_diffs = list()\n",
    "all_diffs_CLAIM = list()\n",
    "\n",
    "conv_diffs = list()\n",
    "conv_diffs_CLAIM = list()\n",
    "\n",
    "not_conv_diffs = list()\n",
    "not_conv_diffs_CLAIM = list()\n",
    "\n",
    "mixed_diffs = list()\n",
    "mixed_diffs_CLAIM = list()\n",
    "\n",
    "for t, m_1, m_2, m_3 in zip(claims, medians_1, medians_2, medians_3):\n",
    "    diff = max([m_1, m_2, m_3]) - min([m_1, m_2, m_3])\n",
    "    all_diffs.append(diff)\n",
    "    all_diffs_CLAIM.append(t)\n",
    "    if t in converged_1 and t in converged_2 and t in converged_3: \n",
    "        print(t, \"\\t%0.3f\" % diff, \"\\tCONVERGED\")\n",
    "        conv_diffs.append(diff)\n",
    "        conv_diffs_CLAIM.append(t)\n",
    "    elif not t in converged_1 and not t in converged_2 and not t in converged_3:\n",
    "        print(t, \"\\t%0.3f\" % diff)\n",
    "        not_conv_diffs.append(diff)\n",
    "        not_conv_diffs_CLAIM.append(t)\n",
    "    else:\n",
    "        print(t, \"\\t%0.3f\" % diff)\n",
    "        mixed_diffs.append(diff)\n",
    "        mixed_diffs_CLAIM.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca6ab0-5626-4bf0-87d9-1115b0df7fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9f8a9af-efef-4344-bb98-b812c9fd21f8",
   "metadata": {},
   "source": [
    "### All claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d927a1db-cdde-447e-9d5d-fae32cff2e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX:\t 0.28\n",
      "MIN:\t 0.01\n",
      "AVG:\t 0.14\n",
      "STD:\t 0.07\n"
     ]
    }
   ],
   "source": [
    "print(\"MAX:\\t %.2f\" % max(all_diffs))\n",
    "print(\"MIN:\\t %.2f\" % min(all_diffs))\n",
    "print(\"AVG:\\t %.2f\" % (sum(all_diffs)/len(all_diffs)))\n",
    "print(\"STD:\\t %.2f\" % np.std(all_diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57752df4-d586-41fa-8228-acfc3b8bec06",
   "metadata": {},
   "source": [
    "### Claims for which threshol-tuning is \"complete\" on all three folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed9ddafd-3d84-4ad9-a804-453d94087252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX:\t 0.12\n",
      "MIN:\t 0.01\n",
      "AVG:\t 0.07\n",
      "STD:\t 0.04\n"
     ]
    }
   ],
   "source": [
    "print(\"MAX:\\t %.2f\" % max(conv_diffs))\n",
    "print(\"MIN:\\t %.2f\" % min(conv_diffs))\n",
    "print(\"AVG:\\t %.2f\" % (sum(conv_diffs)/len(conv_diffs)))\n",
    "print(\"STD:\\t %.2f\" % np.std(conv_diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5dc728-4c52-47c5-9a6c-b5e544b4b116",
   "metadata": {},
   "source": [
    "### Claims for which threshol-tuning is \"complete\" on all none of the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54d73eb4-1def-4d38-8892-e5917c4643ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX:\t 0.28\n",
      "MIN:\t 0.05\n",
      "AVG:\t 0.16\n",
      "STD:\t 0.06\n"
     ]
    }
   ],
   "source": [
    "print(\"MAX:\\t %.2f\" % max(not_conv_diffs))\n",
    "print(\"MIN:\\t %.2f\" % min(not_conv_diffs))\n",
    "print(\"AVG:\\t %.2f\" % (sum(not_conv_diffs)/len(not_conv_diffs)))\n",
    "print(\"STD:\\t %.2f\" % np.std(not_conv_diffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b06eea-7137-45cb-966d-bd51cfec0386",
   "metadata": {},
   "source": [
    "### Claims for which threshol-tuning is \"complete\" on some but not all of the three folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48de5e07-b668-4418-89a3-0721c7f8f8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX:\t 0.11\n",
      "MIN:\t 0.02\n",
      "AVG:\t 0.07\n",
      "STD:\t 0.04\n"
     ]
    }
   ],
   "source": [
    "print(\"MAX:\\t %.2f\" % max(mixed_diffs))\n",
    "print(\"MIN:\\t %.2f\" % min(mixed_diffs))\n",
    "print(\"AVG:\\t %.2f\" % (sum(mixed_diffs)/len(mixed_diffs)))\n",
    "print(\"STD:\\t %.2f\" % np.std(mixed_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac9273c-1058-459a-b2d2-1a62a1dbbb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981cc24e-5da0-445a-916a-e22a607b3ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 3: Using negated claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ad30cb3-a145-49ec-abda-c10c1e5698ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/climate_change/claims_neg.json') as file:\n",
    "    claims_neg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca5e6eaa-3a6c-4c6f-8502-6d1a3ac35218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_nli_scores(row):\n",
    "    dict_pos = {k: row['FSL_BART'][claims[k]] for k in claims}\n",
    "    dict_neg = {k: row['FSL_BART_neg'][claims_neg[k]] for k in claims_neg}\n",
    "    new_dict = dict()\n",
    "    for k in dict_pos:\n",
    "        if dict_neg[k] > dict_pos[k]:\n",
    "            new_dict[claims[k]] = 0.0\n",
    "        else:\n",
    "            new_dict[claims[k]] = dict_pos[k]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b1404aa-54e0-45e5-adba-9ae850065436",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['FSL_BART_pos_and_neg'] = test_df.apply(normalise_nli_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5047d832-ebe3-4a04-9814-207169fde48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/CCC_BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3466509e-189b-4a20-abd7-9fe81de54b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc8cf2e7-adcc-4a71-80ff-1c6c56435d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART_pos_and_neg', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed145ffd-5266-4669-8b15-743007c2d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.70      0.58      0.64        36\n",
      "         1_2       0.82      0.75      0.78        12\n",
      "         1_3       0.60      0.75      0.67        48\n",
      "         1_4       0.83      0.64      0.73        70\n",
      "         1_6       0.94      0.62      0.75        24\n",
      "         1_7       0.52      0.65      0.58        34\n",
      "\n",
      "   micro avg       0.69      0.66      0.68       224\n",
      "   macro avg       0.74      0.67      0.69       224\n",
      "weighted avg       0.73      0.66      0.68       224\n",
      " samples avg       0.05      0.05      0.05       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e2770-c807-4968-9fee-9610f49f1b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e480edd4-d90d-40a6-8755-ed52dc0092fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 4: Adding more claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9bc15ba-caed-4e83-879e-0531af651e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/climate_change/claims_extras.json') as file:\n",
    "    claims_extras = json.load(file)\n",
    "    \n",
    "claims_w_extras = {**claims, **claims_extras}\n",
    "\n",
    "del claims_w_extras[\"class_descr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb6a83ec-5882-4fc0-812b-6dd1d8011493",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/CCC_BART.json') as file:\n",
    "    bart_record = json.load(file)\n",
    "\n",
    "with open('./data/bisection_records/BART_extras.json') as file:\n",
    "    bart_record_extras = json.load(file)\n",
    "    \n",
    "bart_record_w_extras = {**bart_record, **bart_record_extras}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8362d805-8d69-4da0-8667-40e954a06108",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_extras_thresholds = get_thresholds_from_record(bart_record_w_extras, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6614711-fa9d-4c17-adfa-0e868dc640ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART_extras', claims_w_extras, thresholds=bart_extras_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e85c6e1e-befd-4942-8a5a-c917f5531c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.66      0.69      0.68        36\n",
      "         1_2       0.48      0.92      0.63        12\n",
      "         1_3       0.62      0.85      0.72        48\n",
      "         1_4       0.60      0.79      0.68        70\n",
      "         1_6       0.77      0.71      0.74        24\n",
      "         1_7       0.37      0.68      0.47        34\n",
      "\n",
      "   micro avg       0.57      0.77      0.65       224\n",
      "   macro avg       0.58      0.77      0.65       224\n",
      "weighted avg       0.59      0.77      0.66       224\n",
      " samples avg       0.06      0.06      0.06       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3a38c-ff54-49ff-b7ef-6f2ac09d2687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a677c76-885c-45f2-9716-7bd5cc1c9b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
