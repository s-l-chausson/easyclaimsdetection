{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6908d60d-6fbc-4558-a99e-b7ceda5b3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e433cf8b-6b15-4e17-8959-480fccfb906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b66b983-9ba0-49ec-a84e-4ecea1f0552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa4e41aa-0bfb-4b20-b84d-cf90ad9825d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27037f20-9c6d-47d4-9748-44ae40fa5e10",
   "metadata": {},
   "source": [
    "# Experiments from paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a93a6-4c00-4444-8559-42dede9f34b1",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2fdacf-34cd-4110-8839-7ebe88cea32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(distr, start, end, step):\n",
    "    x = np.arange(start, end, step)\n",
    "    exp_f = np.exp(distr)\n",
    "    alpha = exp_f.sum() * 0.5\n",
    "    try:\n",
    "        median_low = x[exp_f.cumsum() <= alpha][-1]\n",
    "    except IndexError:\n",
    "        median_low = start\n",
    "    try:\n",
    "        median_high = x[::-1][exp_f[::-1].cumsum() < alpha][-1]\n",
    "    except IndexError:\n",
    "        median_high = end\n",
    "    median_avg = (median_low + median_high) / 2\n",
    "    return median_avg\n",
    "\n",
    "def get_thresholds_from_record(record, start=0, end=1, step=0.01):\n",
    "    thresholds = dict()\n",
    "    for claim in record:\n",
    "        thresholds[claim] = {'threshold': get_median(record[claim]['distributions'][-1], start, end, step)}\n",
    "    return thresholds\n",
    "\n",
    "def keep_only_top_claim(scores_dict):\n",
    "    new_dict = dict()\n",
    "    \n",
    "    for cl in CLASSES:\n",
    "        rel_claims = [t for t in claims if t[:3] == cl]\n",
    "        cl_dict = {t: scores_dict[t] for t in rel_claims}\n",
    "        highest_t = max(cl_dict, key = cl_dict.get)\n",
    "        for t in rel_claims:\n",
    "            if t == highest_t:\n",
    "                new_dict[t] = scores_dict[t]\n",
    "            else:\n",
    "                new_dict[t] = 0\n",
    "    return new_dict\n",
    "\n",
    "def get_multi_pred(row, column, claims_dict, thresholds=None, black_list=None, min_length=1):\n",
    "    if thresholds is None:\n",
    "        thresholds = {t: {'threshold': 0.0} for t in claims_dict}\n",
    "    if black_list is None:\n",
    "        black_list = []\n",
    "    result = list()\n",
    "    if isinstance(row[column], list):\n",
    "        zsl_scores = {k:row[column][0][claims_dict[k]] for k in claims_dict}\n",
    "    else:\n",
    "        zsl_scores = {k:row[column][claims_dict[k]] for k in claims_dict}\n",
    "    for c in CLASSES:\n",
    "        sub_pred = {k: zsl_scores[k] for k in zsl_scores if k[:3] == c and not k in black_list}\n",
    "        if len([k for k in sub_pred if sub_pred[k] > thresholds[k]['threshold']]) >= min_length:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_binary_pred(row, claim_class, column, claims_dict, thresholds=None, black_list=None, min_length=1):\n",
    "    if thresholds is None:\n",
    "        thresholds = {t: {'threshold': 0.0} for t in claims_dict}\n",
    "    if black_list is None:\n",
    "        black_list = []\n",
    "    result = list()\n",
    "    if isinstance(row[column], list):\n",
    "        zsl_scores = {k:row[column][0][claims_dict[k]] for k in claims_dict}\n",
    "    else:\n",
    "        zsl_scores = {k:row[column][claims_dict[k]] for k in claims_dict}\n",
    "\n",
    "    sub_pred = {k: zsl_scores[k] for k in zsl_scores if k[:3] == claim_class and not k in black_list}\n",
    "    if len([k for k in sub_pred if sub_pred[k] > thresholds[k]['threshold']]) >= min_length:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224a128-1c5b-410d-823c-ea2b37eb276c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Climate Change Contrarianism detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4349c3d7-31fe-4b52-9163-f4f3b38b8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('./data/climate_change/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35bb3b44-80ac-4a3e-a06a-86cbd2457a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['1_1', '1_2', '1_3', '1_4', '1_6', '1_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4095a39c-ce30-496d-a648-2423e9545794",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/climate_change/claims.json\") as file:\n",
    "    claims = json.load(file)\n",
    "\n",
    "claims_descr = claims[\"class_descr\"]\n",
    "del claims[\"class_descr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a21dd9-66b2-49e4-89cb-eaec2b5ca967",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_claims = {claims[k]: k for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b65e3-7177-4659-9704-76d63e1154b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3cb0859-bb4b-4dcd-b6cb-21a2241e291b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 1: Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08852f7d-cb3d-4525-8827-9fc73313acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.67      0.86      0.76        36\n",
      "         1_2       0.56      0.42      0.48        12\n",
      "         1_3       0.63      0.35      0.45        48\n",
      "         1_4       0.54      0.89      0.67        70\n",
      "         1_6       0.69      0.92      0.79        24\n",
      "         1_7       0.40      0.47      0.43        34\n",
      "\n",
      "   micro avg       0.57      0.68      0.62       224\n",
      "   macro avg       0.58      0.65      0.60       224\n",
      "weighted avg       0.58      0.68      0.60       224\n",
      " samples avg       0.06      0.06      0.06       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['BERT'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ed55f7-e15d-428d-a888-fe485d559b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dc3f40e-452a-444a-8e64-aed82014f7a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 2: SBERT cosine similarity with threshold-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6dfb20c-2f7d-43e5-8a97-bc6be4afc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/CCC_SBERT.json') as file:\n",
    "    sbert_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47544a9f-4d21-44cb-bb8b-cbd6ea5450e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_thresholds = get_thresholds_from_record(sbert_record, start=-1, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865e3421-dade-4a1b-b71c-28528f6c7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'sbert_cosine', claims, thresholds=sbert_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89e76f01-6f37-4f81-abab-3c1156c5ed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.43      0.89      0.58        36\n",
      "         1_2       0.20      0.08      0.12        12\n",
      "         1_3       0.64      0.15      0.24        48\n",
      "         1_4       0.40      0.44      0.42        70\n",
      "         1_6       0.52      0.96      0.68        24\n",
      "         1_7       0.50      0.50      0.50        34\n",
      "\n",
      "   micro avg       0.45      0.50      0.47       224\n",
      "   macro avg       0.45      0.50      0.42       224\n",
      "weighted avg       0.47      0.50      0.43       224\n",
      " samples avg       0.04      0.04      0.04       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "619d4384-38ab-4592-8b09-7b2121787f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in sbert_record:\n",
    "    datapoints += sbert_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f48fc-b77f-417a-bc88-b387c2bbfa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17b80dc3-9fab-4b04-86cc-068fad5676f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 3: BART MNLI model with unique threshold (Zero-Shot approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a36455f-ce4c-46e9-aeb7-540eb460ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_thresholds = {k: {'threshold': 0.5} for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ec4aa7-a634-4131-8555-de1835568d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=artificial_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac0158df-e835-4b96-af55-b0671e03b3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.22      0.69      0.34        36\n",
      "         1_2       0.06      1.00      0.11        12\n",
      "         1_3       0.03      0.98      0.06        48\n",
      "         1_4       0.47      0.80      0.59        70\n",
      "         1_6       0.29      0.96      0.45        24\n",
      "         1_7       0.01      0.97      0.03        34\n",
      "\n",
      "   micro avg       0.05      0.88      0.09       224\n",
      "   macro avg       0.18      0.90      0.26       224\n",
      "weighted avg       0.23      0.88      0.31       224\n",
      " samples avg       0.03      0.07      0.04       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ff50f-ae6d-4e0e-b63b-baecc77100d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bcf1ade-7798-42d4-9ea5-a86155afc426",
   "metadata": {},
   "source": [
    "### Baseline 4: BART MNLI model with Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b827f5fe-776d-47ac-9369-d811f5ad28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [5, 10, 20, 40, 80, 160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1a0cf04-2eba-4e3e-a088-01391c7e3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_thresholds = {k: {'threshold': 0.5} for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaa9e16b-ea93-4f70-9a76-bee57bc0fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 0.161\n",
      "10 : 0.220\n",
      "20 : 0.205\n",
      "40 : 0.154\n",
      "80 : 0.193\n",
      "160 : 0.188\n"
     ]
    }
   ],
   "source": [
    "for samp_size in sample_sizes:\n",
    "    test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'Temp_Scaling_BART_' + str(samp_size), claims, thresholds=artificial_thresholds), axis=1)\n",
    "    print(samp_size, ': %.3f' % f1_score(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d9137-57c1-4527-a889-f44ba79c4ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23226e4f-021e-4c94-949a-43a5ff094c09",
   "metadata": {},
   "source": [
    "### Baseline 5: Llama 2 70b model with prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "529e6cad-9c38-4860-b94c-ed89ec293709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_pred(row, column, claims_dict, black_list=None, min_length=1):\n",
    "    if black_list is None:\n",
    "        black_list = []\n",
    "    result = list()\n",
    "    zsl_scores = {k:row[column][claims_dict[k]] for k in claims_dict}\n",
    "    for c in CLASSES:\n",
    "        sub_pred = {k: zsl_scores[k] for k in zsl_scores if k[:3] == c and not k in black_list}\n",
    "        if len([k for k in sub_pred if sub_pred[k].lower().strip() == \"yes\"]) >= min_length:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6b82c80-8f3f-4a1d-8814-85b37a5dd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_llama_pred(x, 'Llama-2', claims), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81552dc5-1fd8-46b4-9240-be05e150a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.03      0.97      0.06        36\n",
      "         1_2       0.04      0.92      0.08        12\n",
      "         1_3       0.10      0.75      0.18        48\n",
      "         1_4       0.07      0.94      0.13        70\n",
      "         1_6       0.05      0.88      0.09        24\n",
      "         1_7       0.03      0.65      0.05        34\n",
      "\n",
      "   micro avg       0.05      0.85      0.09       224\n",
      "   macro avg       0.05      0.85      0.10       224\n",
      "weighted avg       0.06      0.85      0.11       224\n",
      " samples avg       0.03      0.07      0.04       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258b1ff-b1e0-4341-bb64-7bbbfcb12415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70b42a7a-198b-4801-bcc9-812ba8f3651c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ours 1: Few-shots NLI approach using BART MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49c0e892-7889-46d2-af95-50c8294c201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/CCC_BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc26b15b-2a17-4144-9233-2d737074436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c9de37a-b426-4d64-bd88-bf0833fcf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38eb15d2-37ad-4e21-addf-432ebc0da32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1_1       0.68      0.64      0.66        36\n",
      "         1_2       0.82      0.75      0.78        12\n",
      "         1_3       0.61      0.77      0.68        48\n",
      "         1_4       0.80      0.64      0.71        70\n",
      "         1_6       0.88      0.62      0.73        24\n",
      "         1_7       0.51      0.65      0.57        34\n",
      "\n",
      "   micro avg       0.68      0.67      0.68       224\n",
      "   macro avg       0.72      0.68      0.69       224\n",
      "weighted avg       0.71      0.67      0.68       224\n",
      " samples avg       0.05      0.05      0.05       224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cf05b51-5d53-4df3-843e-d05710801084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in bart_record:\n",
    "    if k in [\"1_4_0_1\"]:\n",
    "        continue\n",
    "    datapoints += bart_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b507ed9-3986-4e22-af40-084e9b0350b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52d67d5a-816d-4e9e-abf3-bab90ff95e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Topic and stance classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "165f6fb2-549a-4dd6-8020-75ceac287bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('./data/topic_stance/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12894ae8-47e8-4567-9cc2-bd342496c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_TOPIC = ['1', '2', '3', '4', '5']\n",
    "CLASSES_STANCE = ['1A', '1F', '1N', '2A', '2F', '2N', '3A', '3F', '3N', '4A', '4F', '4N', '5A', '5F', '5N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "202fa37f-7a9e-43f4-b1d7-e1c777d8dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/topic_stance/claims_topic.json\") as file:\n",
    "    claims_topic = json.load(file)\n",
    "    \n",
    "with open(\"./data/topic_stance/claims_stance.json\") as file:\n",
    "    claims_stance = json.load(file)\n",
    "    \n",
    "claims = {**claims_topic, **claims_stance}\n",
    "\n",
    "claims_descr = claims[\"class_descr\"]\n",
    "del claims[\"class_descr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb9dad97-5bad-4500-8090-9f231c70602e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_claims = {claims[k]: k for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4df9c831-1ecc-47c1-a7e6-2e1fdcadf758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transformation(x, threshold):\n",
    "    if x <= threshold:\n",
    "        return x * (0.5 / threshold)\n",
    "    else:\n",
    "        return 0.5 + (x - threshold) * (0.5 / (1 - threshold))\n",
    "    \n",
    "    \n",
    "def get_normed_scores(zsl_dict, thresholds, inverse_claims):\n",
    "    new_results = dict()\n",
    "    for trait in zsl_dict:\n",
    "        if not trait in inverse_claims:\n",
    "            continue\n",
    "        new_results[trait] = custom_transformation(zsl_dict[trait], thresholds[inverse_claims[trait]]['threshold'])\n",
    "    return new_results\n",
    "\n",
    "\n",
    "def get_avg_normed_topic_scores(normed_zsl_dict, classes_list, inverse_claims):\n",
    "    new_results = dict()\n",
    "    for c in classes_list:\n",
    "        temp = [normed_zsl_dict[trait] for trait in normed_zsl_dict if inverse_claims[trait].split(\"_\")[0] == c]\n",
    "        if len(temp) > 0:\n",
    "            new_results[c] = sum(temp) / len(temp)\n",
    "    return new_results\n",
    "    \n",
    "\n",
    "def get_topic_pred_multiclass(avg_normed_ZSL_scores):\n",
    "    return max(avg_normed_ZSL_scores, key=avg_normed_ZSL_scores.get)\n",
    "\n",
    "def get_stance_pred(normed_zsl_dict, topic, traits):\n",
    "    traits_anti = [traits[t] for t in traits if t[:2] == (topic + \"A\")]\n",
    "    detected_anti = [normed_zsl_dict[t] for t in traits_anti if normed_zsl_dict[t] > 0.5]\n",
    "    traits_favor = [traits[t] for t in traits if t[:2] == (topic + \"F\")]\n",
    "    detected_favor = [normed_zsl_dict[t] for t in traits_favor if normed_zsl_dict[t] > 0.5]\n",
    "    if len(detected_anti) > len(detected_favor):\n",
    "        return topic + \"A\"\n",
    "    elif len(detected_favor) > len(detected_anti):\n",
    "        return topic + \"F\"\n",
    "    if len(detected_favor) == 0:\n",
    "        return topic + \"N\"\n",
    "    avg_scores_anti = sum(detected_anti) / len(detected_anti)\n",
    "    avg_scores_favour = sum(detected_favor) / len(detected_favor)\n",
    "    if avg_scores_anti > (1.05 * avg_scores_favour):\n",
    "        return topic + \"A\"\n",
    "    elif avg_scores_favour > (1.05 * avg_scores_anti):\n",
    "        return topic + \"F\"\n",
    "    return topic + \"N\"\n",
    "    return max(normed_zsl_dict, key=normed_zsl_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738ebe9-56da-4158-a7ae-c856fddf7a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2174be5e-12fd-4af0-931b-11b1149d3cff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 1: Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67f59b84-60ac-464a-bc13-4cf969bb9cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1A       0.79      0.74      0.76       160\n",
      "          1F       0.29      0.19      0.23        32\n",
      "          1N       0.23      0.32      0.26        28\n",
      "          2A       0.00      0.00      0.00        11\n",
      "          2F       0.85      0.91      0.88       123\n",
      "          2N       0.26      0.20      0.23        35\n",
      "          3A       0.68      0.54      0.60       183\n",
      "          3F       0.26      0.60      0.36        58\n",
      "          3N       0.32      0.16      0.21        44\n",
      "          4A       0.66      0.76      0.71       172\n",
      "          4F       0.58      0.67      0.62        45\n",
      "          4N       0.32      0.36      0.34        78\n",
      "          5A       0.69      0.47      0.56       189\n",
      "          5F       0.55      0.24      0.33        46\n",
      "          5N       0.10      0.20      0.13        45\n",
      "\n",
      "    accuracy                           0.55      1249\n",
      "   macro avg       0.44      0.42      0.41      1249\n",
      "weighted avg       0.59      0.55      0.56      1249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['topic_stance_annot'].to_list(), test_df['BERT_topic_stance'].to_list(), target_names=CLASSES_STANCE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a3e3c1-94f3-4561-b201-d3665d8805c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 2: SBERT cosine similarity with threshold-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d739f07-7f5f-4c44-b211-b2a75471e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/TS_SBERT_topic.json') as file:\n",
    "    sbert_record_topic = json.load(file)\n",
    "    \n",
    "with open('./data/bisection_records/TS_SBERT_stance.json') as file:\n",
    "    sbert_record_stance = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "046d8c1d-9081-4174-ad93-81ea4fa061e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_topic_thresholds = get_thresholds_from_record(sbert_record_topic, start=-1, end=1)\n",
    "sbert_stance_thresholds = get_thresholds_from_record(sbert_record_stance, start=-1, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0d6977b-7b82-4181-9652-0632ba49dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['normed_sbert_topic'] = test_df[\"sbert_cosine_topic\"].apply(lambda x: get_normed_scores(x, sbert_topic_thresholds, inverse_claims))\n",
    "test_df['normed_sbert_stance'] = test_df[\"sbert_cosine_stance\"].apply(lambda x: get_normed_scores(x, sbert_stance_thresholds, inverse_claims))\n",
    "test_df['avg_normed_sbert_topic'] = test_df[\"normed_sbert_topic\"].apply(lambda x: get_avg_normed_topic_scores(x, CLASSES_TOPIC, inverse_claims))\n",
    "test_df['pred_topic'] = test_df['avg_normed_sbert_topic'].apply(get_topic_pred_multiclass)\n",
    "test_df['pred_stance'] = test_df.apply(lambda x: get_stance_pred(x['normed_sbert_stance'], x['pred_topic'], claims_stance), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4046d2e-8747-43fc-b9a6-a72846d89f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1A       0.72      0.76      0.74       160\n",
      "          1F       0.80      0.12      0.22        32\n",
      "          1N       0.05      0.14      0.07        28\n",
      "          2A       0.00      0.00      0.00        11\n",
      "          2F       0.84      0.92      0.88       123\n",
      "          2N       0.25      0.49      0.33        35\n",
      "          3A       0.62      0.57      0.60       183\n",
      "          3F       0.00      0.00      0.00        58\n",
      "          3N       0.12      0.43      0.18        44\n",
      "          4A       0.73      0.51      0.60       172\n",
      "          4F       0.50      0.02      0.04        45\n",
      "          4N       0.27      0.53      0.35        78\n",
      "          5A       0.71      0.52      0.60       189\n",
      "          5F       0.00      0.00      0.00        46\n",
      "          5N       0.07      0.07      0.07        45\n",
      "\n",
      "    accuracy                           0.49      1249\n",
      "   macro avg       0.38      0.34      0.31      1249\n",
      "weighted avg       0.54      0.49      0.49      1249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['topic_stance_annot'].to_list(), test_df['pred_stance'].to_list(), target_names=CLASSES_STANCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b646924-2133-4fc8-8110-f6a1fb100fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1271"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in sbert_record_topic:\n",
    "    datapoints += sbert_record_topic[k]['texts']\n",
    "    \n",
    "for k in sbert_record_stance:\n",
    "    datapoints += sbert_record_stance[k]['texts']\n",
    "    \n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1403487-b9ed-4b59-a06c-cafc0674e14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f68302-508e-460b-864c-055ac3b07ffd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 3: BART MNLI model with unique threshold (Zero-Shot approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f561586-3b95-4eae-b454-9e76f5722259",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_thresholds = {k: {'threshold': 0.5} for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8311ae32-b246-4105-bf4f-6921b8607fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['normed_BART_topic'] = test_df[\"FSL_BART_topic\"].apply(lambda x: get_normed_scores(x, artificial_thresholds, inverse_claims))\n",
    "test_df['normed_BART_stance'] = test_df[\"FSL_BART_stance\"].apply(lambda x: get_normed_scores(x, artificial_thresholds, inverse_claims))\n",
    "test_df['avg_normed_BART_topic'] = test_df[\"normed_BART_topic\"].apply(lambda x: get_avg_normed_topic_scores(x, CLASSES_TOPIC, inverse_claims))\n",
    "test_df['pred_topic'] = test_df['avg_normed_BART_topic'].apply(get_topic_pred_multiclass)\n",
    "test_df['pred_stance'] = test_df.apply(lambda x: get_stance_pred(x['normed_BART_stance'], x['pred_topic'], claims_stance), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ce73153-7a60-4c2c-baab-136beb29c8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1A       0.76      0.76      0.76       160\n",
      "          1F       0.58      0.56      0.57        32\n",
      "          1N       0.05      0.07      0.06        28\n",
      "          2A       0.67      0.18      0.29        11\n",
      "          2F       0.73      0.98      0.84       123\n",
      "          2N       0.21      0.09      0.12        35\n",
      "          3A       0.71      0.25      0.37       183\n",
      "          3F       0.20      0.88      0.32        58\n",
      "          3N       0.14      0.39      0.20        44\n",
      "          4A       0.89      0.51      0.65       172\n",
      "          4F       0.76      0.71      0.74        45\n",
      "          4N       0.32      0.40      0.35        78\n",
      "          5A       0.89      0.16      0.28       189\n",
      "          5F       0.18      0.43      0.26        46\n",
      "          5N       0.25      0.02      0.04        45\n",
      "\n",
      "    accuracy                           0.47      1249\n",
      "   macro avg       0.49      0.43      0.39      1249\n",
      "weighted avg       0.63      0.47      0.47      1249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['topic_stance_annot'].to_list(), test_df['pred_stance'].to_list(), target_names=CLASSES_STANCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865145d0-1f14-469e-9022-67e68933c0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d35bd13-d0ae-4ba0-b886-44a8a2690c56",
   "metadata": {},
   "source": [
    "### Baseline 4: BART MNLI model with Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b70777a-ef54-4cec-a577-343213e899fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [5, 10, 20, 40, 80, 160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0ac9bc8-3ac1-4cd4-929a-f0b16d23274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_thresholds = {k: {'threshold': 0.5} for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9ce57b5-14a5-412b-ae18-a0903f6e65f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Target', 'Tweet', 'Stance', 'FSL_BART_stance', 'FSL_BART_topic',\n",
       "       'sbert_cosine_topic', 'sbert_cosine_stance', 'topic_stance_annot',\n",
       "       'topic_annot', '1_annot', '2_annot', '3_annot', '4_annot', '5_annot',\n",
       "       '1A_annot', '1F_annot', '2A_annot', '2F_annot', '3A_annot', '3F_annot',\n",
       "       '4A_annot', '4F_annot', '5A_annot', '5F_annot', 'BERT_topic',\n",
       "       'BERT_topic_stance', 'Temp_Scaling_BART_5_topic',\n",
       "       'Temp_Scaling_BART_10_topic', 'Temp_Scaling_BART_20_topic',\n",
       "       'Temp_Scaling_BART_40_topic', 'Temp_Scaling_BART_80_topic',\n",
       "       'Temp_Scaling_BART_160_topic', 'Temp_Scaling_BART_5_stance',\n",
       "       'Temp_Scaling_BART_10_stance', 'Temp_Scaling_BART_20_stance',\n",
       "       'Temp_Scaling_BART_40_stance', 'Temp_Scaling_BART_80_stance',\n",
       "       'Temp_Scaling_BART_160_stance', 'Llama-2', 'Llama-2_STANCE',\n",
       "       'normed_sbert_topic', 'normed_sbert_stance', 'avg_normed_sbert_topic',\n",
       "       'pred_topic', 'pred_stance', 'normed_BART_topic', 'normed_BART_stance',\n",
       "       'avg_normed_BART_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4e42dd3-6d46-483a-8906-6dcf411195fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 0.420\n",
      "10 : 0.420\n",
      "20 : 0.418\n",
      "40 : 0.415\n",
      "80 : 0.417\n",
      "160 : 0.416\n"
     ]
    }
   ],
   "source": [
    "for samp_size in sample_sizes:\n",
    "    test_df['normed_TempScal_topic'] = test_df[\"Temp_Scaling_BART_\" + str(samp_size) + \"_topic\"].apply(lambda x: get_normed_scores(x, artificial_thresholds, inverse_claims))\n",
    "    test_df['normed_TempScal_stance'] = test_df[\"Temp_Scaling_BART_\" + str(samp_size) + \"_stance\"].apply(lambda x: get_normed_scores(x, artificial_thresholds, inverse_claims))\n",
    "    test_df['avg_normed_TempScal_topic'] = test_df[\"normed_TempScal_topic\"].apply(lambda x: get_avg_normed_topic_scores(x, CLASSES_TOPIC, inverse_claims))\n",
    "    test_df['pred_topic'] = test_df['avg_normed_TempScal_topic'].apply(get_topic_pred_multiclass)\n",
    "    test_df['pred_stance'] = test_df.apply(lambda x: get_stance_pred(x['normed_TempScal_stance'], x['pred_topic'], claims_stance), axis=1)\n",
    "    print(samp_size, ': %.3f' % f1_score(test_df['topic_stance_annot'].to_list(), test_df['pred_stance'].to_list(), average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f768e-21c2-43e2-a77e-a3007853f119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ccf79d5-0906-4473-9c20-4edd3776344d",
   "metadata": {},
   "source": [
    "### Baseline 5: Llama 2 70b model with prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6892e6b4-77c8-4997-97a6-106a33a1bb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Target', 'Tweet', 'Stance', 'FSL_BART_stance', 'FSL_BART_topic',\n",
       "       'sbert_cosine_topic', 'sbert_cosine_stance', 'topic_stance_annot',\n",
       "       'topic_annot', '1_annot', '2_annot', '3_annot', '4_annot', '5_annot',\n",
       "       '1A_annot', '1F_annot', '2A_annot', '2F_annot', '3A_annot', '3F_annot',\n",
       "       '4A_annot', '4F_annot', '5A_annot', '5F_annot', 'BERT_topic',\n",
       "       'BERT_topic_stance', 'Temp_Scaling_BART_5_topic',\n",
       "       'Temp_Scaling_BART_10_topic', 'Temp_Scaling_BART_20_topic',\n",
       "       'Temp_Scaling_BART_40_topic', 'Temp_Scaling_BART_80_topic',\n",
       "       'Temp_Scaling_BART_160_topic', 'Temp_Scaling_BART_5_stance',\n",
       "       'Temp_Scaling_BART_10_stance', 'Temp_Scaling_BART_20_stance',\n",
       "       'Temp_Scaling_BART_40_stance', 'Temp_Scaling_BART_80_stance',\n",
       "       'Temp_Scaling_BART_160_stance', 'Llama-2', 'Llama-2_STANCE',\n",
       "       'normed_sbert_topic', 'normed_sbert_stance', 'avg_normed_sbert_topic',\n",
       "       'pred_topic', 'pred_stance', 'normed_BART_topic', 'normed_BART_stance',\n",
       "       'avg_normed_BART_topic', 'normed_TempScal_topic',\n",
       "       'normed_TempScal_stance', 'avg_normed_TempScal_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "419e9370-c73b-4552-9ade-00a84f0faf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2idx = {\n",
    "    \"Atheism\": \"1\",\n",
    "    \"Climate Change is a Real Concern\": \"2\",\n",
    "    \"Feminist Movement\": \"3\",\n",
    "    \"Hillary Clinton\": \"4\",\n",
    "    \"Legalization of Abortion\": \"5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ab6e406-93f5-4d52-907b-6307c0f896f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_pred(stance_preds, stance_annots, topic_annot):\n",
    "    result = list()\n",
    "    \n",
    "    for topic in target2idx:\n",
    "        if topic in stance_preds and topic == topic_annot: \n",
    "            if stance_preds[topic].lower() == \"anti\":\n",
    "                result += [1, 0, 0]\n",
    "            elif stance_preds[topic].lower() == \"pro\":\n",
    "                result += [0, 1, 0]\n",
    "            else:\n",
    "                result += [0, 0, 1]\n",
    "        else:\n",
    "            result += [0, 0, 0]\n",
    "    \n",
    "    sub_results = list()\n",
    "    \n",
    "    for p,a in zip(result, stance_annots):\n",
    "        if a == 0:\n",
    "            sub_results.append(0)\n",
    "        else:\n",
    "            sub_results.append(p)\n",
    "            \n",
    "    return sub_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9e689b4-9e8c-4507-b4ad-bf493d677c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['topic_stance_annot_multi'] = test_df['topic_stance_annot'].apply(lambda x: [1 if k == x else 0 for k in CLASSES_STANCE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e876d8eb-c877-4789-bc9b-f9711bf3d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_stance'] = test_df.apply(lambda x: get_llama_pred(x[\"Llama-2_STANCE\"], x[\"topic_stance_annot_multi\"], x[\"Target\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "299ad1c9-70ce-47d5-87ef-07797a548b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1A       0.00      0.00      0.00       160\n",
      "          1F       1.00      0.03      0.06        32\n",
      "          1N       0.00      0.00      0.00        28\n",
      "          2A       0.00      0.00      0.00        11\n",
      "          2F       1.00      0.07      0.14       123\n",
      "          2N       1.00      0.34      0.51        35\n",
      "          3A       0.00      0.00      0.00       183\n",
      "          3F       1.00      0.14      0.24        58\n",
      "          3N       1.00      0.09      0.17        44\n",
      "          4A       1.00      0.01      0.01       172\n",
      "          4F       1.00      0.04      0.09        45\n",
      "          4N       1.00      0.04      0.07        78\n",
      "          5A       1.00      0.01      0.02       189\n",
      "          5F       1.00      0.13      0.23        46\n",
      "          5N       1.00      0.16      0.27        45\n",
      "\n",
      "   micro avg       1.00      0.04      0.08      1249\n",
      "   macro avg       0.73      0.07      0.12      1249\n",
      "weighted avg       0.69      0.04      0.08      1249\n",
      " samples avg       0.04      0.04      0.04      1249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['topic_stance_annot_multi'].to_list(), test_df['pred_stance'].to_list(), target_names=CLASSES_STANCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07180260-43ad-4e24-a780-ef3028ad047b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cc8705f-bd1c-4368-9976-ebbab3586cf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ours 1: Few-shots NLI approach using BART MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7916dfe-33b0-4d03-a2d3-bed91bc9798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/TS_BART_topic.json') as file:\n",
    "    bart_record_topic = json.load(file)\n",
    "    \n",
    "with open('./data/bisection_records/TS_BART_stance.json') as file:\n",
    "    bart_record_stance = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4e7fa41-670e-41d9-a450-c41e13db96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_topic_thresholds = get_thresholds_from_record(bart_record_topic, start=0, end=1)\n",
    "bart_stance_thresholds = get_thresholds_from_record(bart_record_stance, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45e3a555-158d-4694-be1a-43613c9b4101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_0': {'threshold': 0.44},\n",
       " '1_1': {'threshold': 0.37},\n",
       " '1_2': {'threshold': 0.21000000000000002},\n",
       " '1_3': {'threshold': 0.16999999999999998},\n",
       " '1_4': {'threshold': 0.14},\n",
       " '2_0': {'threshold': 0.46},\n",
       " '2_1': {'threshold': 0.46},\n",
       " '2_2': {'threshold': 0.41000000000000003},\n",
       " '2_3': {'threshold': 0.31},\n",
       " '2_4': {'threshold': 0.19},\n",
       " '3_0': {'threshold': 0.53},\n",
       " '3_1': {'threshold': 0.44},\n",
       " '3_2': {'threshold': 0.65},\n",
       " '3_3': {'threshold': 0.6},\n",
       " '3_4': {'threshold': 0.27},\n",
       " '4_0': {'threshold': 0.47},\n",
       " '4_1': {'threshold': 0.63},\n",
       " '4_2': {'threshold': 0.11},\n",
       " '4_3': {'threshold': 0.16999999999999998},\n",
       " '4_4': {'threshold': 0.26},\n",
       " '5_0': {'threshold': 0.12},\n",
       " '5_1': {'threshold': 0.5700000000000001},\n",
       " '5_2': {'threshold': 0.1},\n",
       " '5_3': {'threshold': 0.16},\n",
       " '5_4': {'threshold': 0.05}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_topic_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e78cb6e3-b3ae-4b78-a291-2bbcfd03b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['normed_BART_topic'] = test_df[\"FSL_BART_topic\"].apply(lambda x: get_normed_scores(x, bart_topic_thresholds, inverse_claims))\n",
    "test_df['normed_BART_stance'] = test_df[\"FSL_BART_stance\"].apply(lambda x: get_normed_scores(x, bart_stance_thresholds, inverse_claims))\n",
    "test_df['avg_normed_BART_topic'] = test_df[\"normed_BART_topic\"].apply(lambda x: get_avg_normed_topic_scores(x, CLASSES_TOPIC, inverse_claims))\n",
    "test_df['pred_topic'] = test_df['avg_normed_BART_topic'].apply(get_topic_pred_multiclass)\n",
    "test_df['pred_stance'] = test_df.apply(lambda x: get_stance_pred(x['normed_BART_stance'], x['pred_topic'], claims_stance), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b12b726d-a4b7-4a02-a692-3aae21d8592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1A       0.77      0.74      0.75       160\n",
      "          1F       0.61      0.59      0.60        32\n",
      "          1N       0.15      0.39      0.22        28\n",
      "          2A       1.00      0.18      0.31        11\n",
      "          2F       0.78      0.92      0.85       123\n",
      "          2N       0.28      0.31      0.29        35\n",
      "          3A       0.76      0.35      0.48       183\n",
      "          3F       0.45      0.53      0.49        58\n",
      "          3N       0.13      0.55      0.21        44\n",
      "          4A       0.91      0.53      0.67       172\n",
      "          4F       0.76      0.78      0.77        45\n",
      "          4N       0.34      0.42      0.38        78\n",
      "          5A       0.75      0.53      0.62       189\n",
      "          5F       0.42      0.17      0.25        46\n",
      "          5N       0.16      0.27      0.20        45\n",
      "\n",
      "    accuracy                           0.54      1249\n",
      "   macro avg       0.55      0.48      0.47      1249\n",
      "weighted avg       0.66      0.54      0.57      1249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['topic_stance_annot'].to_list(), test_df['pred_stance'].to_list(), target_names=CLASSES_STANCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36aaf9b6-93ad-4931-a5c2-302c163f6bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in bart_record:\n",
    "    if k in [\"1_4_0_1\"]:\n",
    "        continue\n",
    "    datapoints += bart_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed51c9-89e6-42a6-a3a3-b31b686e1f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367e96a-3882-4efb-904f-a1e7575a217d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8390c0c-6731-4c43-b34b-cb10db5af553",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Depressive symptoms detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e9f2960-9da7-4def-b71c-777bd24a78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('./data/depression/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "58a5d015-5499-4633-8631-5b3d17f925d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop_duplicates(subset=[\"Sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f48fd4d-37b9-4715-8d6c-b447758dce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', \n",
    "    '17', '18', '19', '20', '21'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfcf526a-b9ba-401f-af1f-79dda50ddc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/depression/claims.json\") as file:\n",
    "    claims = json.load(file)\n",
    "\n",
    "claims_descr = claims[\"class_descr\"]\n",
    "del claims[\"class_descr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2857ef50-fb31-4fe4-95ac-de1785095e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_claims = {claims[k]: k for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e29343c1-dc96-451a-bb59-8f7bd68f55bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"multi_annot\"] = test_df.apply(lambda x: [x[C + \"_annot\"] for C in CLASSES], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65d662-10ab-4d5b-a2ff-e4b0712bd919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "823a4761-4b7e-42a7-86c5-e73460aad081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detected_claims(zsl_dict, thresholds, claims):\n",
    "    detected = list()\n",
    "    for claim_idx in claims:\n",
    "        if zsl_dict[claims[claim_idx]] >= thresholds[claim_idx]['threshold']:\n",
    "            detected.append(claim_idx)\n",
    "    return detected \n",
    "\n",
    "\n",
    "def get_pred(detected, classes):\n",
    "    preds = list()\n",
    "    for group in classes:\n",
    "        rel = [d for d in detected if d.split(\"_\")[0] == group]\n",
    "        if len(rel) > 0:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb69ad-170b-4792-be75-147efbbad1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43786448-d7e8-4a30-a24c-ba8d0f37937a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 1: Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff15f56c-6401-43a0-94e4-30c05f0a2445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.56      0.62        64\n",
      "           2       0.00      0.00      0.00        28\n",
      "           3       1.00      0.19      0.32        31\n",
      "           4       0.28      0.76      0.40        29\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.00      0.00      0.00        13\n",
      "           7       0.83      0.16      0.26        32\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00         7\n",
      "          10       0.00      0.00      0.00        15\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.00      0.00      0.00        11\n",
      "          13       0.00      0.00      0.00        10\n",
      "          14       1.00      0.06      0.12        16\n",
      "          15       0.00      0.00      0.00         4\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00        20\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         5\n",
      "          20       1.00      0.14      0.25         7\n",
      "          21       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.48      0.22      0.30       324\n",
      "   macro avg       0.23      0.09      0.09       324\n",
      "weighted avg       0.41      0.22      0.23       324\n",
      " samples avg       0.06      0.04      0.05       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['BERT_pred'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502f0ca-6a6f-4c0f-9099-b39d1935868d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b34170e-1baf-46fe-b7d9-822671e27b03",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 2: SBERT cosine similarity with threshold-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92090a0f-e6e6-4c55-9661-3226665fd9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/D_SBERT.json') as file:\n",
    "    sbert_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ef1dad4e-a906-4de2-a070-2c42f70229d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_thresholds = get_thresholds_from_record(sbert_record, start=-1, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed8a9b65-6f78-45b0-8e21-424e834d804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['detected'] = test_df['sbert_cosine'].apply(lambda x: get_detected_claims(x, sbert_thresholds, claims))\n",
    "test_df['pred_multi'] = test_df['detected'].apply(lambda x: get_pred(x, CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43942b8d-7ee6-4eb6-a2d6-05dbafcec4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.22      0.33        64\n",
      "           2       1.00      0.04      0.07        28\n",
      "           3       0.33      0.06      0.11        31\n",
      "           4       0.33      0.03      0.06        29\n",
      "           5       1.00      0.19      0.32        16\n",
      "           6       0.00      0.00      0.00        13\n",
      "           7       1.00      0.12      0.22        32\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.25      0.86      0.39         7\n",
      "          10       1.00      0.47      0.64        15\n",
      "          11       0.00      0.00      0.00        10\n",
      "          12       0.00      0.00      0.00        11\n",
      "          13       0.00      0.00      0.00        10\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.33      0.25      0.29         4\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00        20\n",
      "          18       0.25      1.00      0.40         1\n",
      "          19       0.00      0.00      0.00         5\n",
      "          20       1.00      0.29      0.44         7\n",
      "          21       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.52      0.13      0.21       324\n",
      "   macro avg       0.34      0.17      0.16       324\n",
      "weighted avg       0.51      0.13      0.18       324\n",
      " samples avg       0.03      0.02      0.03       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb9680f6-af72-4bb1-ac8a-1d71aec84b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in sbert_record:\n",
    "    datapoints += sbert_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271740c2-2f2e-4b5d-b82b-46cc155d7619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee751993-06e9-4f47-b38f-10026f768374",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 3: BART MNLI model with unique threshold (Zero-Shot approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa14ed96-00d4-4df2-a861-ce96f72cd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_thresholds = {k: {'threshold': 0.5} for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca6042a9-37a3-4bdf-809d-08abb5409cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['detected'] = test_df['FSL_BART'].apply(lambda x: get_detected_claims(x, artificial_thresholds, claims))\n",
    "test_df['pred_multi'] = test_df['detected'].apply(lambda x: get_pred(x, CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "64a105ad-2305-4bf4-8563-77e84332be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26        64\n",
      "           2       0.06      0.89      0.11        28\n",
      "           3       0.05      0.97      0.10        31\n",
      "           4       0.01      0.28      0.03        29\n",
      "           5       0.04      0.94      0.08        16\n",
      "           6       0.02      1.00      0.04        13\n",
      "           7       0.07      1.00      0.13        32\n",
      "           8       0.00      1.00      0.01         3\n",
      "           9       0.16      0.43      0.23         7\n",
      "          10       0.08      0.87      0.14        15\n",
      "          11       0.06      0.80      0.12        10\n",
      "          12       0.08      0.73      0.14        11\n",
      "          13       0.01      0.80      0.03        10\n",
      "          14       0.07      1.00      0.12        16\n",
      "          15       0.00      0.50      0.01         4\n",
      "          16       0.05      0.50      0.09         2\n",
      "          17       0.12      0.80      0.20        20\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.02      1.00      0.05         5\n",
      "          20       0.02      0.86      0.04         7\n",
      "          21       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.04      0.85      0.07       324\n",
      "   macro avg       0.05      0.73      0.09       324\n",
      "weighted avg       0.07      0.85      0.13       324\n",
      " samples avg       0.02      0.12      0.03       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51b961-a57d-4833-8f7c-d5b06c76c9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce06e6c5-acc9-48c2-a1f9-7a4f35b34c4f",
   "metadata": {},
   "source": [
    "### Baseline 4: BART MNLI model with Temperature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57285abe-ab93-4074-b1a2-0a9a5bac9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [5, 10, 20, 40, 80, 160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52a027be-5887-4bd8-89e4-ee0214027403",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_thresholds = {k: {'threshold': 0.5} for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6e2b107-8bb9-473d-885a-49c78ef1d61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 : 0.153\n",
      "10 : 0.179\n",
      "20 : 0.194\n",
      "40 : 0.218\n",
      "80 : 0.252\n",
      "160 : 0.268\n"
     ]
    }
   ],
   "source": [
    "for samp_size in sample_sizes:\n",
    "    test_df['detected'] = test_df[\"Temp_Scaling_BART_\" + str(samp_size)].apply(lambda x: get_detected_claims(x, artificial_thresholds, claims))\n",
    "    test_df['pred_multi'] = test_df['detected'].apply(lambda x: get_pred(x, CLASSES))\n",
    "    print(samp_size, ': %.3f' % f1_score(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e1742-6462-49d5-b282-9c793dfa48bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c14771-5060-40bd-8f21-d03e376159b5",
   "metadata": {},
   "source": [
    "### Baseline 5: Llama 2 (70b model) with prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7104e58c-6819-4de0-9c30-7b75001b7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detected_claims_LLAMA(zsl_dict, claims):\n",
    "    detected = list()\n",
    "    for claim_idx in claims:\n",
    "        if zsl_dict[claims[claim_idx]].lower().strip() == \"yes\":\n",
    "            detected.append(claim_idx)\n",
    "    return detected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e39e013-dc93-4e4a-9523-6ea3ebbe51e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['detected'] = test_df['Llama-2'].apply(lambda x: get_detected_claims_LLAMA(x, claims))\n",
    "test_df['pred_multi'] = test_df['detected'].apply(lambda x: get_pred(x, CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1ebdc68-11dc-484f-a786-57271d2c1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.83      0.55        64\n",
      "           2       0.14      0.86      0.24        28\n",
      "           3       0.28      0.61      0.38        31\n",
      "           4       0.05      0.21      0.08        29\n",
      "           5       0.13      0.69      0.21        16\n",
      "           6       0.07      0.23      0.11        13\n",
      "           7       0.36      0.81      0.50        32\n",
      "           8       0.01      0.33      0.02         3\n",
      "           9       0.08      0.57      0.14         7\n",
      "          10       0.10      0.67      0.17        15\n",
      "          11       0.05      0.80      0.09        10\n",
      "          12       0.07      0.45      0.12        11\n",
      "          13       0.02      0.20      0.04        10\n",
      "          14       0.14      0.94      0.24        16\n",
      "          15       0.02      0.50      0.04         4\n",
      "          16       0.02      1.00      0.05         2\n",
      "          17       0.09      0.65      0.16        20\n",
      "          18       0.05      1.00      0.09         1\n",
      "          19       0.03      0.80      0.06         5\n",
      "          20       0.06      0.86      0.11         7\n",
      "          21       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.11      0.66      0.19       324\n",
      "   macro avg       0.10      0.62      0.16       324\n",
      "weighted avg       0.19      0.66      0.28       324\n",
      " samples avg       0.03      0.10      0.04       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f06a41-54ce-4986-8752-3acc570d0c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb8f3949-4104-4dbd-8977-e5c4ece199ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ours 1: Few-shots NLI approach using BART MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee733c5e-308b-4318-b26a-3e15917d7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/D_BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9f26c10f-fc07-4407-bf70-ffd813432bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "06e82aad-e8ce-4eac-b535-cd4fd26d8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['detected'] = test_df['FSL_BART'].apply(lambda x: get_detected_claims(x, bart_thresholds, claims))\n",
    "test_df['pred_multi'] = test_df['detected'].apply(lambda x: get_pred(x, CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3b25e07-aa0c-4a3b-9be9-057f72dd1cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.48      0.54        64\n",
      "           2       0.36      0.32      0.34        28\n",
      "           3       0.39      0.52      0.44        31\n",
      "           4       0.08      0.03      0.05        29\n",
      "           5       1.00      0.31      0.48        16\n",
      "           6       0.18      0.15      0.17        13\n",
      "           7       0.26      0.72      0.38        32\n",
      "           8       0.10      0.33      0.15         3\n",
      "           9       0.43      0.43      0.43         7\n",
      "          10       0.75      0.20      0.32        15\n",
      "          11       0.14      0.10      0.12        10\n",
      "          12       0.27      0.27      0.27        11\n",
      "          13       0.29      0.20      0.24        10\n",
      "          14       0.39      0.75      0.51        16\n",
      "          15       0.09      0.25      0.13         4\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.22      0.35      0.27        20\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.08      0.20      0.12         5\n",
      "          20       0.50      0.29      0.36         7\n",
      "          21       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.33      0.38      0.35       324\n",
      "   macro avg       0.29      0.28      0.25       324\n",
      "weighted avg       0.39      0.38      0.35       324\n",
      " samples avg       0.05      0.06      0.05       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d631b252-0521-4a2e-9b95-9b653db411cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in bart_record:\n",
    "    if k in [\"1_4_0_1\"]:\n",
    "        continue\n",
    "    datapoints += bart_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2616db1-e84b-4597-9d69-1e2eaa91db28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de45f7e-46c2-41a5-bb35-f7b5a38e7c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82505ab-7794-41ef-9126-05743f98fd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
