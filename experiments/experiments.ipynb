{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6908d60d-6fbc-4558-a99e-b7ceda5b3537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sandrinechausson/Documents/easyclaimsdetection/experiments'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e433cf8b-6b15-4e17-8959-480fccfb906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b66b983-9ba0-49ec-a84e-4ecea1f0552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27037f20-9c6d-47d4-9748-44ae40fa5e10",
   "metadata": {},
   "source": [
    "# Experiments from paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed46fad-21a0-4d82-90dc-ba4b1a6ac098",
   "metadata": {},
   "source": [
    "##Â Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4349c3d7-31fe-4b52-9163-f4f3b38b8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('../data/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35bb3b44-80ac-4a3e-a06a-86cbd2457a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['0_0', '1_1', '1_2', '1_3', '1_4', '1_6', '1_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a278898-28c6-4ead-9d51-2adbd5cb6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/claims/claims.json') as file:\n",
    "    claims = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a93a6-4c00-4444-8559-42dede9f34b1",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d2fdacf-34cd-4110-8839-7ebe88cea32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(distr, start, end, step):\n",
    "    x = np.arange(start, end, step)\n",
    "    exp_f = np.exp(distr)\n",
    "    alpha = exp_f.sum() * 0.5\n",
    "    try:\n",
    "        median_low = x[exp_f.cumsum() <= alpha][-1]\n",
    "    except IndexError:\n",
    "        median_low = start\n",
    "    try:\n",
    "        median_high = x[::-1][exp_f[::-1].cumsum() < alpha][-1]\n",
    "    except IndexError:\n",
    "        median_high = end\n",
    "    median_avg = (median_low + median_high) / 2\n",
    "    return median_avg\n",
    "\n",
    "def get_thresholds_from_record(record, start=0, end=1, step=0.01):\n",
    "    thresholds = dict()\n",
    "    for claim in record:\n",
    "        thresholds[claim] = {'threshold': get_median(record[claim]['distributions'][-1], start, end, step)}\n",
    "    return thresholds\n",
    "\n",
    "def keep_only_top_claim(scores_dict):\n",
    "    new_dict = dict()\n",
    "    \n",
    "    for cl in CLASSES[1:]:\n",
    "        rel_claims = [t for t in claims if t[:3] == cl]\n",
    "        cl_dict = {t: scores_dict[t] for t in rel_claims}\n",
    "        highest_t = max(cl_dict, key = cl_dict.get)\n",
    "        for t in rel_claims:\n",
    "            if t == highest_t:\n",
    "                new_dict[t] = scores_dict[t]\n",
    "            else:\n",
    "                new_dict[t] = 0\n",
    "    return new_dict\n",
    "\n",
    "def get_multi_pred(row, column, claims_dict, thresholds=None, black_list=None, min_length=1, top_len=2,  min_avgs=None, top_claim_only=False):\n",
    "    if thresholds is None:\n",
    "        thresholds = {t: {'threshold': 0.0} for t in claims_dict}\n",
    "    if min_avgs is None:\n",
    "        min_avgs = {c: {'threshold': 0.0} for c in CLASSES[1:]}\n",
    "    if black_list is None:\n",
    "        black_list = []\n",
    "    result = list()\n",
    "    if isinstance(row[column], list):\n",
    "        zsl_scores = {k:row[column][0][claims_dict[k]] for k in claims_dict}\n",
    "    else:\n",
    "        zsl_scores = {k:row[column][claims_dict[k]] for k in claims_dict}\n",
    "    if top_claim_only:\n",
    "        zsl_scores = keep_only_top_claim(zsl_scores)\n",
    "    for c in CLASSES[1:]:\n",
    "        sub_pred = {k: zsl_scores[k] for k in zsl_scores if k[:3] == c and not k in black_list}\n",
    "        top_traits = sorted([k for k in sub_pred], reverse=True, key=lambda item: sub_pred[item])[:top_len]\n",
    "        top_scores = sorted([sub_pred[k] for k in sub_pred], reverse=True)[:top_len]\n",
    "        if c in min_avgs:\n",
    "            avg_threshold = min_avgs[c]['threshold']\n",
    "        else:\n",
    "            avg_threshold = sum([min_avgs[t]['threshold'] for t in top_traits]) / top_len\n",
    "        if len([k for k in sub_pred if sub_pred[k] > thresholds[k]['threshold']]) >= min_length and (sum(top_scores) / top_len) > avg_threshold:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    if len([e for e in result if e ==1]) > 0:\n",
    "        result = [0] + result\n",
    "    else:\n",
    "        result = [1] + result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f064246-2dc7-45a3-ac66-9724518d1195",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Section 4.1: Evaluation against baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb0859-bb4b-4dcd-b6cb-21a2241e291b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 1: Fine-tuned RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08852f7d-cb3d-4525-8827-9fc73313acb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.97      0.98      2395\n",
      "         1_1       0.73      0.89      0.80        36\n",
      "         1_2       0.56      0.42      0.48        12\n",
      "         1_3       0.88      0.58      0.70        48\n",
      "         1_4       0.68      0.81      0.74        70\n",
      "         1_6       0.85      0.71      0.77        24\n",
      "         1_7       0.41      0.65      0.50        34\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2619\n",
      "   macro avg       0.73      0.72      0.71      2619\n",
      "weighted avg       0.96      0.95      0.95      2619\n",
      " samples avg       0.95      0.95      0.95      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['RoBERTa'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7403649-aa0c-42d4-869d-a2de70b484e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 2: Fine-tuned RoBERTa w/ limited training data (RoBERTa_MINI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4f8dd2-d1ef-4c4d-b8d5-b9b077defaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.94      0.99      0.96      2395\n",
      "         1_1       0.56      0.75      0.64        36\n",
      "         1_2       0.00      0.00      0.00        12\n",
      "         1_3       0.00      0.00      0.00        48\n",
      "         1_4       0.62      0.14      0.23        70\n",
      "         1_6       0.92      0.46      0.61        24\n",
      "         1_7       0.00      0.00      0.00        34\n",
      "\n",
      "   micro avg       0.93      0.92      0.93      2619\n",
      "   macro avg       0.43      0.33      0.35      2619\n",
      "weighted avg       0.89      0.92      0.90      2619\n",
      " samples avg       0.93      0.93      0.93      2619\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandrinechausson/Documents/easyclaimsdetection/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['RoBERTa_MINI'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3f40e-452a-444a-8e64-aed82014f7a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 3: SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dfb20c-2f7d-43e5-8a97-bc6be4afc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/SBERT.json') as file:\n",
    "    sbert_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47544a9f-4d21-44cb-bb8b-cbd6ea5450e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_thresholds = get_thresholds_from_record(sbert_record, start=-1, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865e3421-dade-4a1b-b71c-28528f6c7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'sbert_cosine', claims, thresholds=sbert_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e76f01-6f37-4f81-abab-3c1156c5ed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.96      0.96      0.96      2395\n",
      "         1_1       0.41      0.92      0.57        36\n",
      "         1_2       0.20      0.08      0.12        12\n",
      "         1_3       0.64      0.15      0.24        48\n",
      "         1_4       0.40      0.44      0.42        70\n",
      "         1_6       0.52      0.96      0.68        24\n",
      "         1_7       0.50      0.50      0.50        34\n",
      "\n",
      "   micro avg       0.91      0.92      0.92      2619\n",
      "   macro avg       0.52      0.57      0.50      2619\n",
      "weighted avg       0.92      0.92      0.92      2619\n",
      " samples avg       0.92      0.93      0.92      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "619d4384-38ab-4592-8b09-7b2121787f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in sbert_record:\n",
    "    datapoints += sbert_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b80dc3-9fab-4b04-86cc-068fad5676f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Baseline 4: BART MNLI model with unique threshold (Zero-Shot Learning approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a36455f-ce4c-46e9-aeb7-540eb460ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_thresholds = {k: {'threshold': 0.95} for k in claims}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31ec4aa7-a634-4131-8555-de1835568d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=artificial_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac0158df-e835-4b96-af55-b0671e03b3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.92      0.94      2395\n",
      "         1_1       1.00      0.33      0.50        36\n",
      "         1_2       0.53      0.75      0.62        12\n",
      "         1_3       0.60      0.75      0.67        48\n",
      "         1_4       0.75      0.47      0.58        70\n",
      "         1_6       0.93      0.54      0.68        24\n",
      "         1_7       0.10      0.65      0.17        34\n",
      "\n",
      "   micro avg       0.88      0.89      0.88      2619\n",
      "   macro avg       0.70      0.63      0.60      2619\n",
      "weighted avg       0.94      0.89      0.91      2619\n",
      " samples avg       0.89      0.89      0.89      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b42a7a-198b-4801-bcc9-812ba8f3651c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ours 1: Few-shots NLI approach using BART MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c0e892-7889-46d2-af95-50c8294c201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc26b15b-2a17-4144-9233-2d737074436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c9de37a-b426-4d64-bd88-bf0833fcf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38eb15d2-37ad-4e21-addf-432ebc0da32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.98      0.98      2395\n",
      "         1_1       0.68      0.64      0.66        36\n",
      "         1_2       0.82      0.75      0.78        12\n",
      "         1_3       0.61      0.77      0.68        48\n",
      "         1_4       0.68      0.70      0.69        70\n",
      "         1_6       0.88      0.62      0.73        24\n",
      "         1_7       0.51      0.65      0.57        34\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2619\n",
      "   macro avg       0.74      0.73      0.73      2619\n",
      "weighted avg       0.95      0.95      0.95      2619\n",
      " samples avg       0.95      0.96      0.95      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cf05b51-5d53-4df3-843e-d05710801084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in bart_record:\n",
    "    datapoints += bart_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239a5933-a8a9-4eb6-9ff6-f27cc0eaa59c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ours 2: Few-shots NLI approach using DistilBART MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a5cc789-092f-4d70-94ba-974b1e2790a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/DistilBART.json') as file:\n",
    "    distilbart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a400120b-583e-4205-8bc1-c1f2314efe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbart_thresholds = get_thresholds_from_record(distilbart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ae7dc03-c2af-4fec-aae9-a24ac9f49f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_DistilBART', claims, thresholds=distilbart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc4575ed-5ec4-428b-aaaa-13825323030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.97      0.97      2395\n",
      "         1_1       0.68      0.75      0.71        36\n",
      "         1_2       0.48      0.92      0.63        12\n",
      "         1_3       0.73      0.50      0.59        48\n",
      "         1_4       0.58      0.71      0.64        70\n",
      "         1_6       0.83      0.79      0.81        24\n",
      "         1_7       0.35      0.65      0.46        34\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2619\n",
      "   macro avg       0.66      0.76      0.69      2619\n",
      "weighted avg       0.95      0.94      0.94      2619\n",
      " samples avg       0.94      0.95      0.94      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "128081ca-e0bf-4ba1-a597-3de09ec3e955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in distilbart_record:\n",
    "    datapoints += distilbart_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5d217-129e-49d2-8e5a-7c24a43ee129",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ours 3: Few-shots NLI approach using DeBERTa MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4120f0a8-ef8f-435d-934f-412f073ce912",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/DeBERTa.json') as file:\n",
    "    deberta_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52c0f456-90f6-4d41-bb3b-aabc983cdd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deberta_thresholds = get_thresholds_from_record(deberta_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d45aaa3-1995-491d-9bf9-1bcb193a4d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_DeBERTa', claims, thresholds=deberta_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddfd27f9-4eb7-488c-80f3-86feef9e0ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.93      0.95      2395\n",
      "         1_1       0.64      0.64      0.64        36\n",
      "         1_2       0.48      0.83      0.61        12\n",
      "         1_3       0.52      0.52      0.52        48\n",
      "         1_4       0.68      0.79      0.73        70\n",
      "         1_6       0.65      0.71      0.68        24\n",
      "         1_7       0.13      0.68      0.21        34\n",
      "\n",
      "   micro avg       0.89      0.91      0.90      2619\n",
      "   macro avg       0.58      0.73      0.62      2619\n",
      "weighted avg       0.94      0.91      0.92      2619\n",
      " samples avg       0.90      0.91      0.90      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58719523-f603-4730-b7d1-859b8539f95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapoints = list()\n",
    "for k in deberta_record:\n",
    "    datapoints += deberta_record[k]['texts']\n",
    "len(set(datapoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47051494-4d99-4bfd-91be-01808515b89a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 2: Changing classification requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faadd5b-df13-4904-b438-59391dce3c0e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### A. Requiring at least 2 claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0798b5c9-e239-4ae6-8e17-7b1832074ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3302785b-5c53-4a8f-9bca-85c7af942cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff2b3711-e31d-488a-a6f4-e756c890ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds, min_length=2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2d4c294-6de3-4991-bad5-cd45d580318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.94      1.00      0.97      2395\n",
      "         1_1       0.93      0.39      0.55        36\n",
      "         1_2       1.00      0.08      0.15        12\n",
      "         1_3       0.78      0.15      0.25        48\n",
      "         1_4       0.89      0.36      0.51        70\n",
      "         1_6       0.86      0.25      0.39        24\n",
      "         1_7       0.60      0.09      0.15        34\n",
      "\n",
      "   micro avg       0.94      0.93      0.94      2619\n",
      "   macro avg       0.86      0.33      0.42      2619\n",
      "weighted avg       0.93      0.93      0.92      2619\n",
      " samples avg       0.94      0.94      0.94      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88301b5b-3205-4ff0-8b2e-8c2448227f54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### B. Considering only top 1 claim ONLY during classification step (same thresholds as in initial set up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed11bd3a-3607-4289-9a69-ffe9af6c3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c76b173-d10e-4b9b-bee0-9a3bd45c057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f895bd8-5a52-4334-8ce7-b9cd19f74320",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds, top_claim_only=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cebea3b-ffd3-45c8-a63a-32ec9fe020c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.98      0.98      2395\n",
      "         1_1       0.77      0.64      0.70        36\n",
      "         1_2       0.86      0.50      0.63        12\n",
      "         1_3       0.60      0.75      0.67        48\n",
      "         1_4       0.70      0.69      0.69        70\n",
      "         1_6       0.88      0.62      0.73        24\n",
      "         1_7       0.47      0.53      0.50        34\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2619\n",
      "   macro avg       0.75      0.67      0.70      2619\n",
      "weighted avg       0.95      0.95      0.95      2619\n",
      " samples avg       0.95      0.95      0.95      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd73c6-1723-4819-bfa3-cb6feec29ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### C. Considering only top 1 claim ONLY during threshold-tuning step (new thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9acdfea4-0a68-4fa3-9647-d1023ec05b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART_top_1_only.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caf1f97e-e389-46a2-ad17-a87a2ca4c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5784c8e-03b7-4318-9260-4a219b87e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37fef2ff-4ecf-405e-acf0-12819d4fa1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.99      0.98      2395\n",
      "         1_1       0.73      0.61      0.67        36\n",
      "         1_2       0.89      0.67      0.76        12\n",
      "         1_3       0.60      0.75      0.67        48\n",
      "         1_4       0.80      0.64      0.71        70\n",
      "         1_6       0.94      0.62      0.75        24\n",
      "         1_7       0.52      0.47      0.49        34\n",
      "\n",
      "   micro avg       0.95      0.96      0.95      2619\n",
      "   macro avg       0.78      0.68      0.72      2619\n",
      "weighted avg       0.95      0.96      0.95      2619\n",
      " samples avg       0.96      0.96      0.96      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284fc568-1c05-4926-af50-77c89601c6da",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### D. Considering only top 1 claim during BOTH threshold-tuning and classification steps (new thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "344fb164-3502-4471-85c7-0eef6b3e9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART_top_1_only.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47136dd6-e173-4a50-833d-0f293bee55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c044d95b-f722-4d0f-842c-e7aac3db18b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, thresholds=bart_thresholds, top_claim_only=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4db44ad-f794-4448-a469-97f6d9d8f670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.99      0.98      2395\n",
      "         1_1       0.91      0.56      0.69        36\n",
      "         1_2       0.86      0.50      0.63        12\n",
      "         1_3       0.60      0.75      0.67        48\n",
      "         1_4       0.84      0.59      0.69        70\n",
      "         1_6       0.94      0.62      0.75        24\n",
      "         1_7       0.53      0.47      0.50        34\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2619\n",
      "   macro avg       0.81      0.64      0.70      2619\n",
      "weighted avg       0.95      0.95      0.95      2619\n",
      " samples avg       0.96      0.96      0.95      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e22475-1df7-484f-acda-649e10d6aebb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### E. Average of top 2 claims ONLY during classification step (same thresholds as in initial set up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b14ec3a4-1eb8-4839-94da-257587549f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3733e509-592b-4744-a0d7-44c3d9909348",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9557d9da-88c8-4c42-ae7f-39314b4e2fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, min_length=2, min_avgs=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ccef718-fcca-4e70-a30f-76e29ed2e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.95      1.00      0.97      2395\n",
      "         1_1       0.90      0.53      0.67        36\n",
      "         1_2       1.00      0.33      0.50        12\n",
      "         1_3       0.85      0.23      0.36        48\n",
      "         1_4       0.84      0.44      0.58        70\n",
      "         1_6       0.86      0.25      0.39        24\n",
      "         1_7       0.80      0.24      0.36        34\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2619\n",
      "   macro avg       0.88      0.43      0.55      2619\n",
      "weighted avg       0.94      0.94      0.93      2619\n",
      " samples avg       0.95      0.94      0.94      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e2cdc-0c30-4148-8631-3fdbd5599422",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### F. Average of top 2 claims during BOTH the threshold-tuning and classification steps (new thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63476038-fca5-41bc-81db-3cb95aaeda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART_top_2_avg.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ab09e23-38a1-4b0e-8663-06c69ef94ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e700668e-731f-4899-a4ae-46c1cf6553d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', claims, top_len=2, min_avgs=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67ee9761-c613-472e-9f70-c6256852ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.95      1.00      0.97      2395\n",
      "         1_1       0.89      0.44      0.59        36\n",
      "         1_2       1.00      0.33      0.50        12\n",
      "         1_3       0.80      0.33      0.47        48\n",
      "         1_4       0.82      0.39      0.52        70\n",
      "         1_6       0.75      0.12      0.21        24\n",
      "         1_7       0.86      0.18      0.29        34\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2619\n",
      "   macro avg       0.87      0.40      0.51      2619\n",
      "weighted avg       0.94      0.94      0.93      2619\n",
      " samples avg       0.94      0.94      0.94      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318f3492-4acd-48b0-83ea-4696dcd8f397",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 3: Using negated claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7da18115-d393-489e-a64f-8a2efa000c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/claims/claims_neg.json') as file:\n",
    "    claims_neg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0926cc8f-a33f-421c-b423-a927a83ff747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_nli_scores(row):\n",
    "    dict_pos = {k: row['FSL_BART'][claims[k]] for k in claims}\n",
    "    dict_neg = {k: row['FSL_BART_neg'][claims_neg[k]] for k in claims_neg}\n",
    "    new_dict = dict()\n",
    "    for k in dict_pos:\n",
    "        if dict_neg[k] > dict_pos[k]:\n",
    "            new_dict[claims[k]] = 0.0\n",
    "        else:\n",
    "            new_dict[claims[k]] = dict_pos[k]\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bb4dc0d-42be-4e1f-b348-6372853a7338",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['FSL_BART_pos_and_neg'] = test_df.apply(normalise_nli_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "454a701e-7602-497f-a1d9-122d38017e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60a1d2ad-9e2c-447f-94f0-1bda7ae5f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac7238b7-d5dd-40f0-9206-c6dcc04151d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART_pos_and_neg', claims, thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42cc50ec-0c45-4375-8669-55477742650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.98      0.98      2395\n",
      "         1_1       0.70      0.58      0.64        36\n",
      "         1_2       0.82      0.75      0.78        12\n",
      "         1_3       0.60      0.75      0.67        48\n",
      "         1_4       0.68      0.70      0.69        70\n",
      "         1_6       0.94      0.62      0.75        24\n",
      "         1_7       0.52      0.65      0.58        34\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2619\n",
      "   macro avg       0.75      0.72      0.73      2619\n",
      "weighted avg       0.95      0.95      0.95      2619\n",
      " samples avg       0.95      0.96      0.95      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffcb7f0-2b13-4277-8fad-1add05297bb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 4: Adding more claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c12bd8c-8d48-4bd1-9ac1-7d149d5bb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/claims/claims_extras.json') as file:\n",
    "    claims_extras = json.load(file)\n",
    "    \n",
    "claims_w_extras = {**claims, **claims_extras}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0bd2f32d-9b7c-4f8a-8575-e5a7ab12cf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART.json') as file:\n",
    "    bart_record = json.load(file)\n",
    "\n",
    "with open('../data/bisection_records/BART_extras.json') as file:\n",
    "    bart_record_extras = json.load(file)\n",
    "    \n",
    "bart_record_w_extras = {**bart_record, **bart_record_extras}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "01a77146-8586-44ae-8e20-09623dcef66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_extras_thresholds = get_thresholds_from_record(bart_record_w_extras, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea539add-e13e-46ec-a053-f01610375bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART_extras', claims_w_extras, thresholds=bart_extras_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f68e555-f385-480d-9324-73e8373e2bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.96      0.97      2395\n",
      "         1_1       0.66      0.69      0.68        36\n",
      "         1_2       0.48      0.92      0.63        12\n",
      "         1_3       0.62      0.85      0.72        48\n",
      "         1_4       0.55      0.83      0.66        70\n",
      "         1_6       0.77      0.71      0.74        24\n",
      "         1_7       0.37      0.68      0.47        34\n",
      "\n",
      "   micro avg       0.93      0.95      0.94      2619\n",
      "   macro avg       0.63      0.81      0.70      2619\n",
      "weighted avg       0.95      0.95      0.94      2619\n",
      " samples avg       0.94      0.95      0.94      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce93e014-3009-4c54-8e27-9aa19cb7ec4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment 5: Changing the value of p for the Probabilistic Bisection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43553dd9-4185-4884-891f-c823e2dd1b45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### p = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d2897b-34ec-4203-b2bf-298bd391fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART_0-6.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae2048d5-e6f0-452c-b01a-23c2fcb9d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed8c1d7e-39c3-484a-8b41-8e8cae94a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e39dc50d-d7d4-4cb4-99ef-3fea1f3768d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.98      0.91      0.94      2395\n",
      "         1_1       0.68      0.64      0.66        36\n",
      "         1_2       0.46      0.92      0.61        12\n",
      "         1_3       0.61      0.77      0.68        48\n",
      "         1_4       0.62      0.73      0.67        70\n",
      "         1_6       0.83      0.62      0.71        24\n",
      "         1_7       0.10      0.65      0.17        34\n",
      "\n",
      "   micro avg       0.88      0.89      0.88      2619\n",
      "   macro avg       0.61      0.75      0.64      2619\n",
      "weighted avg       0.94      0.89      0.91      2619\n",
      " samples avg       0.89      0.89      0.89      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4023a2e7-a622-4922-b476-4a8f643571b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "432f6022-e63c-4257-a2c1-0c9dadb5ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART_0-8.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a1e9767-b615-4c34-ac2e-7b45c4f5952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a98047c-8c06-453b-8e91-dade03f12b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea040ea3-adc9-45b7-b12c-ab74d9706b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.98      0.98      2395\n",
      "         1_1       0.64      0.64      0.64        36\n",
      "         1_2       0.83      0.83      0.83        12\n",
      "         1_3       0.61      0.77      0.68        48\n",
      "         1_4       0.70      0.69      0.69        70\n",
      "         1_6       0.88      0.62      0.73        24\n",
      "         1_7       0.50      0.56      0.53        34\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      2619\n",
      "   macro avg       0.73      0.73      0.73      2619\n",
      "weighted avg       0.95      0.95      0.95      2619\n",
      " samples avg       0.95      0.95      0.95      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48421ef0-08c3-4608-817c-c5332694a27b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60574aa8-19fe-4c40-96e5-438e15262708",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bisection_records/BART_0-9.json') as file:\n",
    "    bart_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4596cc38-f06c-41ce-b94b-9c2a749f8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_thresholds = get_thresholds_from_record(bart_record, start=0, end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e79f015-7b27-4bf8-87f8-ba9842a31310",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pred_multi'] = test_df.apply(lambda x: get_multi_pred(x, 'FSL_BART', thresholds=bart_thresholds), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "097e4585-c828-4aca-8661-49bcfe5d5756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0_0       0.97      0.97      0.97      2395\n",
      "         1_1       0.64      0.69      0.67        36\n",
      "         1_2       0.69      0.75      0.72        12\n",
      "         1_3       0.57      0.71      0.63        48\n",
      "         1_4       0.82      0.66      0.73        70\n",
      "         1_6       0.88      0.62      0.73        24\n",
      "         1_7       0.35      0.74      0.48        34\n",
      "\n",
      "   micro avg       0.94      0.95      0.94      2619\n",
      "   macro avg       0.70      0.73      0.70      2619\n",
      "weighted avg       0.95      0.95      0.95      2619\n",
      " samples avg       0.95      0.95      0.95      2619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['multi_annot'].to_list(), test_df['pred_multi'].to_list(), target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15294d-2848-49b6-a7e6-21578a7e69d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
