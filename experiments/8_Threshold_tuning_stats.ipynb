{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f79edc-e16b-4adf-9906-9a9d551406a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b103e70f-764f-4fd4-80c4-72cec9d09ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import statistics\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8f2e0-d0ff-457a-af01-572870e8b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8ec609a-aec0-42e4-843b-58b7bba6f3e8",
   "metadata": {},
   "source": [
    "## Load climate change contrarianism data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc83d1d-74b2-4196-80bb-ebf8c1f614f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/CCC_BART.json', 'r') as file:\n",
    "    clim_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec665b4-d48d-4033-90bd-242df43c8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clim = pd.read_pickle('./data/climate_change/training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c70a51-7989-46ed-9cc4-8c0ef39e11ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'claim', '1_1_annot', '1_2_annot', '1_3_annot', '1_4_annot',\n",
       "       '1_6_annot', '1_7_annot', 'FSL_BART', 'multi_annot', 'sbert_cosine',\n",
       "       'FSL_DistilBART', 'FSL_DeBERTa', 'FSL_BART_neg', 'FSL_BART_extras'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c59630-2ebe-42e2-9d85-89ad1eb3d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clim[\"labels_list\"] = df_clim[\"claim\"].apply(lambda x: [t for t in clim_record if x == t[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9ab326-c783-4695-a8da-f16cb12c072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/climate_change/claims.json') as file:\n",
    "    all_traits = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2e79a0d-4666-4424-b052-5f793b6649e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "traits_clim = {k: all_traits[k] for k in clim_record}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941b313-4e74-4916-be52-627a0612080a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f994d4f-4a82-43e2-b601-a9646f845380",
   "metadata": {},
   "source": [
    "## Load SemEval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2cc9d48-e34f-448b-bb3d-37135058f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/TS_BART_topic.json', 'r') as file:\n",
    "    semeval_topic_record = json.load(file)\n",
    "    \n",
    "with open('./data/bisection_records/TS_BART_stance.json', 'r') as file:\n",
    "    semeval_stance_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a194b2d-a2d2-4a42-a3d1-d6489c1e673f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semeval = pd.read_pickle('./data/topic_stance/training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67dd8b81-c586-4760-b604-ca2add05f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semeval[\"FSL_BART\"] = df_semeval.apply(lambda x: {**x[\"FSL_BART_topic\"], **x[\"FSL_BART_stance\"]}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b10ea30b-9246-4d99-9ec2-8bd35cc671ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stances_descr = {\n",
    "    \"1A\": \"Atheism - AGAINST\",\n",
    "    \"1F\": \"Atheism - FAVOR\",\n",
    "    \"2A\": \"Climate Change is a Real Concern - AGAINST\",\n",
    "    \"2F\": \"Climate Change is a Real Concern - FAVOR\",\n",
    "    \"3A\": \"Feminist Movement - AGAINST\",\n",
    "    \"3F\": \"Feminist Movement - FAVOR\",\n",
    "    \"4A\": \"Hillary Clinton - AGAINST\",\n",
    "    \"4F\": \"Hillary Clinton - FAVOR\",\n",
    "    \"5A\": \"Legalization of Abortion - AGAINST\",\n",
    "    \"5F\": \"Legalization of Abortion - FAVOR\",\n",
    "}\n",
    "\n",
    "topics_descr = {\n",
    "    \"1\": \"Atheism\",\n",
    "    \"2\": \"Climate Change is a Real Concern\",\n",
    "    \"3\": \"Feminist Movement\",\n",
    "    \"4\": \"Hillary Clinton\",\n",
    "    \"5\": \"Legalization of Abortion\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8658e24-c0bc-4d42-9e1d-4de2e3649ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_semeval[\"labels_list\"] = df_semeval.apply(lambda x: [t for t in semeval_topic_record if x[\"Target\"] == topics_descr[t[0]]] + [t_2 for t_2 in semeval_stance_record if x[\"Stance\"] != \"NONE\" and x[\"Target\"] + \" - \" + x[\"Stance\"] == stances_descr[t_2[:2]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd43bf4-07b8-4101-aee5-145218be2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/topic_stance/claims_topic.json') as file:\n",
    "    traits_topics = json.load(file)\n",
    "\n",
    "with open('./data/topic_stance/claims_stance.json') as file:\n",
    "    traits_stance = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd07c00b-6b8c-4c7e-b16c-9b1c3bc42487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f524e429-28d7-4e64-8a30-330f8e628360",
   "metadata": {},
   "source": [
    "## Load depression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "690540a1-9b30-465f-a3f4-1935c02387a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/bisection_records/D_BART.json', 'r') as file:\n",
    "    dep_record = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "434b262a-14d2-4d7f-8b79-b67bc4f8c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = sorted(list(set([k.split(\"_\")[0] for k in dep_record])))\n",
    "class2idx = {c:i for i,c in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3da4bfdb-ae1d-4000-973f-5c9dca80fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep = pd.read_pickle('./data/depression/training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "073481a8-bc2a-44da-9168-40ee4442b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep[\"labels_list\"] = df_dep[\"multi_labels\"].apply(lambda x: [t for t in dep_record if x[class2idx[t.split(\"_\")[0]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aa9fa9b-b479-4c03-ad7d-0e881051012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/depression/claims.json') as file:\n",
    "    traits_dep = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b16a13-1533-4a30-9f31-5dbcaed58ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f44b06eb-feef-4fb1-b403-bb4b7db1ba75",
   "metadata": {},
   "source": [
    "## Generate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9548e40f-83a7-4d42-a068-f4300b75cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop = 1\n",
    "step = 0.01\n",
    "x = np.arange(start, stop, step)\n",
    "\n",
    "def find_CI(distrib, low_mass=0.025, high_mass=0.975):\n",
    "    exp_f = np.exp(distrib)\n",
    "    alpha_low = exp_f.sum() * low_mass\n",
    "    alpha_high = exp_f.sum() * high_mass\n",
    "\n",
    "    try:\n",
    "        l_bound_low = x[exp_f.cumsum() <= alpha_low][-1]\n",
    "        l_low_weight = exp_f.cumsum()[int(l_bound_low * 100)]\n",
    "    except IndexError:\n",
    "        l_bound_low = start\n",
    "        l_low_weight = 0.0\n",
    "        \n",
    "    try:\n",
    "        l_bound_high = x[::-1][exp_f[::-1].cumsum() <= alpha_high][-1]\n",
    "        l_high_weight = exp_f.cumsum()[int(l_bound_high * 100)]\n",
    "    except IndexError:\n",
    "        l_bound_high = stop\n",
    "        l_high_weight = 1.0\n",
    "        \n",
    "    l_bound_avg = (l_bound_low + l_bound_high) / 2\n",
    "    \n",
    "    if (l_bound_avg * 1000) % 10 != 0:\n",
    "        round_down = math.floor(int(l_bound_avg * 100))\n",
    "        round_up = math.ceil(int(l_bound_avg * 100))\n",
    "        l_weight = (exp_f.cumsum()[round_down] + exp_f.cumsum()[round_up]) / 2\n",
    "    else:\n",
    "        l_weight = exp_f.cumsum()[int(l_bound_avg * 100)]  \n",
    "        \n",
    "    try:\n",
    "        r_bound_low = x[exp_f.cumsum() <= alpha_high][-1]\n",
    "        r_low_weight = exp_f.cumsum()[int(r_bound_low * 100)]\n",
    "    except IndexError:\n",
    "        r_bound_low = start\n",
    "        r_low_weight = 0.0\n",
    "        \n",
    "    try:\n",
    "        r_bound_high = x[::-1][exp_f[::-1].cumsum() <= alpha_low][-1]\n",
    "        r_high_weight = exp_f.cumsum()[int(r_bound_high * 100)]\n",
    "    except IndexError:\n",
    "        r_bound_high = stop\n",
    "        r_high_weight = 1.0\n",
    "        \n",
    "    r_bound_avg = (r_bound_low + r_bound_high) / 2\n",
    "    \n",
    "    if (r_bound_avg * 1000) % 10 != 0:\n",
    "        round_down = math.floor(int(r_bound_avg * 100))\n",
    "        round_up = math.ceil(int(r_bound_avg * 100))\n",
    "        r_weight = (exp_f.cumsum()[round_down] + exp_f.cumsum()[round_up]) / 2\n",
    "    else:\n",
    "        r_weight = exp_f.cumsum()[int(r_bound_avg * 100)]  \n",
    "\n",
    "    return l_bound_avg, r_bound_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a37cd-4168-4ad9-a2e9-3fe4e4612bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cf25854-d82a-406b-a5d6-193b5a085e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average number of annotations\n",
    "def print_report(record, df_train, traits):\n",
    "    nb_annots = list()\n",
    "    ci_width = list()\n",
    "    sample_size = list()\n",
    "    thresholds_all = list()\n",
    "\n",
    "    conv_claims = list()\n",
    "    conv_nb_annots = list()\n",
    "    conv_ci_width = list()\n",
    "    conv_sample_size = list()\n",
    "    conv_thresholds = list()\n",
    "\n",
    "    not_conv_claims = list()\n",
    "    not_conv_nb_annots = list()\n",
    "    not_conv_ci_width = list()\n",
    "    not_conv_sample_size = list()\n",
    "    not_conv_thresholds = list()\n",
    "\n",
    "    for t in record:\n",
    "        nb = len(record[t][\"annot\"])\n",
    "        nb_annots.append(nb)\n",
    "        l_bound_1, r_bound_1 = find_CI(record[t]['distributions'][-1], low_mass=0.05, high_mass=0.95)\n",
    "        w = r_bound_1 - l_bound_1\n",
    "        ci_width.append(w)\n",
    "        df_sub = df_train[df_train[\"labels_list\"].apply(lambda x: t in x)]\n",
    "        sample_size.append(len(df_sub))\n",
    "        med_l, med_h = find_CI(record[t]['distributions'][-1], low_mass=0.5, high_mass=0.5)\n",
    "        median = (med_l + med_h) / 2\n",
    "        thresholds_all.append(median)\n",
    "\n",
    "        df_train[\"X\"] = df_train[\"FSL_BART\"].apply(lambda x: x[traits[t]])\n",
    "        df_train[\"Y\"] = df_train[\"labels_list\"].apply(lambda x: 1 if t in x else 0)\n",
    "        \n",
    "        if w > 0.20:\n",
    "            not_conv_claims.append(t)\n",
    "            not_conv_nb_annots.append(nb)\n",
    "            not_conv_ci_width.append(w)\n",
    "            not_conv_sample_size.append(len(df_sub))\n",
    "            not_conv_thresholds.append(median)\n",
    "        else:\n",
    "            conv_claims.append(t)\n",
    "            conv_nb_annots.append(nb)\n",
    "            conv_ci_width.append(w)\n",
    "            conv_sample_size.append(len(df_sub))\n",
    "            conv_thresholds.append(median)\n",
    "\n",
    "    nb_claims = len(record)\n",
    "    conv_nb_claims = len(conv_claims)\n",
    "    not_conv_nb_claims = len(not_conv_claims)\n",
    "\n",
    "    print(\"***** ALL *****\")\n",
    "    print()\n",
    "    print(\"Nb claims:\\t\\t\", nb_claims)\n",
    "    print(\"Average nb annots:\\t %.2f\" % (sum(nb_annots) / nb_claims))\n",
    "    print(\"Average CI width:\\t %.2f\" % (sum(ci_width) / nb_claims))\n",
    "    print(\"Average sample size:\\t %.2f\" % (sum(sample_size) / nb_claims))\n",
    "    print(\"Average threshold:\\t %.2f\" % (sum(thresholds_all) / nb_claims))\n",
    "    print(\"Std average threshold:\\t %.2f\" % (np.std(thresholds_all)))\n",
    "    print(\"Max threshold:\\t\\t %.2f\" % (max(thresholds_all)))\n",
    "    print(\"Min threshold:\\t\\t %.2f\" % (min(thresholds_all)))\n",
    "    print()\n",
    "\n",
    "    print(\"***** COMPLETE *****\")\n",
    "    print()\n",
    "    print(\"Nb claims:\\t\\t\", conv_nb_claims)\n",
    "    print(\"Average nb annots:\\t %.2f\" % (sum(conv_nb_annots) / conv_nb_claims))\n",
    "    print(\"Average CI width:\\t %.2f\" % (sum(conv_ci_width) / conv_nb_claims))\n",
    "    print(\"Average sample size:\\t %.2f\" % (sum(conv_sample_size) / conv_nb_claims))\n",
    "    print(\"Average threshold:\\t %.2f\" % (sum(conv_thresholds) / nb_claims))\n",
    "    print(\"Std average threshold:\\t %.2f\" % (np.std(conv_thresholds)))\n",
    "    print(\"Max threshold:\\t\\t %.2f\" % (max(conv_thresholds)))\n",
    "    print(\"Min threshold:\\t\\t %.2f\" % (min(conv_thresholds)))\n",
    "    print()\n",
    "\n",
    "    print(\"***** EARLY STOP *****\")\n",
    "    print()\n",
    "    print(\"Nb claims:\\t\\t\", not_conv_nb_claims)\n",
    "    print(\"Average nb annots:\\t %.2f\" % (sum(not_conv_nb_annots) / not_conv_nb_claims))\n",
    "    print(\"Average CI width:\\t %.2f\" % (sum(not_conv_ci_width) / not_conv_nb_claims))\n",
    "    print(\"Average sample size:\\t %.2f\" % (sum(not_conv_sample_size) / not_conv_nb_claims))\n",
    "    print(\"Average threshold:\\t %.2f\" % (sum(not_conv_thresholds) / nb_claims))\n",
    "    print(\"Std average threshold:\\t %.2f\" % (np.std(not_conv_thresholds)))\n",
    "    print(\"Max threshold:\\t\\t %.2f\" % (max(not_conv_thresholds)))\n",
    "    print(\"Min threshold:\\t\\t %.2f\" % (min(not_conv_thresholds)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6005d6-9200-4421-b273-162cd0b3d228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cb66904-dfb4-4054-81a3-f07288e29f11",
   "metadata": {},
   "source": [
    "## Climate Change Contrarianism detection task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04d4999d-d335-410d-9f75-d90cfe862da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ALL *****\n",
      "\n",
      "Nb claims:\t\t 30\n",
      "Average nb annots:\t 19.63\n",
      "Average CI width:\t 0.38\n",
      "Average sample size:\t 298.33\n",
      "Average threshold:\t 0.76\n",
      "Std average threshold:\t 0.17\n",
      "Max threshold:\t\t 0.99\n",
      "Min threshold:\t\t 0.34\n",
      "\n",
      "***** COMPLETE *****\n",
      "\n",
      "Nb claims:\t\t 9\n",
      "Average nb annots:\t 19.56\n",
      "Average CI width:\t 0.12\n",
      "Average sample size:\t 310.78\n",
      "Average threshold:\t 0.28\n",
      "Std average threshold:\t 0.04\n",
      "Max threshold:\t\t 0.99\n",
      "Min threshold:\t\t 0.86\n",
      "\n",
      "***** EARLY STOP *****\n",
      "\n",
      "Nb claims:\t\t 21\n",
      "Average nb annots:\t 19.67\n",
      "Average CI width:\t 0.49\n",
      "Average sample size:\t 293.00\n",
      "Average threshold:\t 0.47\n",
      "Std average threshold:\t 0.14\n",
      "Max threshold:\t\t 0.90\n",
      "Min threshold:\t\t 0.34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report(clim_record, df_clim, traits_clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec2c03-403d-4ce4-b0c6-142172edbc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f01405fc-83b7-4f9c-98c4-bd89e071e360",
   "metadata": {},
   "source": [
    "## Topic/Stance classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "905f06de-f9e9-42e2-baef-55541d2665cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ALL *****\n",
      "\n",
      "Nb claims:\t\t 85\n",
      "Average nb annots:\t 21.11\n",
      "Average CI width:\t 0.41\n",
      "Average sample size:\t 278.80\n",
      "Average threshold:\t 0.53\n",
      "Std average threshold:\t 0.27\n",
      "Max threshold:\t\t 0.99\n",
      "Min threshold:\t\t 0.05\n",
      "\n",
      "***** COMPLETE *****\n",
      "\n",
      "Nb claims:\t\t 15\n",
      "Average nb annots:\t 29.60\n",
      "Average CI width:\t 0.11\n",
      "Average sample size:\t 264.73\n",
      "Average threshold:\t 0.10\n",
      "Std average threshold:\t 0.42\n",
      "Max threshold:\t\t 0.99\n",
      "Min threshold:\t\t 0.05\n",
      "\n",
      "***** EARLY STOP *****\n",
      "\n",
      "Nb claims:\t\t 70\n",
      "Average nb annots:\t 19.29\n",
      "Average CI width:\t 0.47\n",
      "Average sample size:\t 281.81\n",
      "Average threshold:\t 0.43\n",
      "Std average threshold:\t 0.23\n",
      "Max threshold:\t\t 0.95\n",
      "Min threshold:\t\t 0.10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report({ **semeval_topic_record, **semeval_stance_record}, df_semeval, {**traits_topics, **traits_stance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed367584-54b9-4270-a057-7f7c61f38bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a0dd294-dc02-4f4c-b8f0-fef674f2d301",
   "metadata": {},
   "source": [
    "## Depressive symptoms detection task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f481cb5b-0d1f-462e-ada3-1c227c7989e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** ALL *****\n",
      "\n",
      "Nb claims:\t\t 64\n",
      "Average nb annots:\t 11.16\n",
      "Average CI width:\t 0.23\n",
      "Average sample size:\t 31.44\n",
      "Average threshold:\t 0.93\n",
      "Std average threshold:\t 0.08\n",
      "Max threshold:\t\t 0.99\n",
      "Min threshold:\t\t 0.61\n",
      "\n",
      "***** COMPLETE *****\n",
      "\n",
      "Nb claims:\t\t 42\n",
      "Average nb annots:\t 13.21\n",
      "Average CI width:\t 0.08\n",
      "Average sample size:\t 32.57\n",
      "Average threshold:\t 0.64\n",
      "Std average threshold:\t 0.02\n",
      "Max threshold:\t\t 0.99\n",
      "Min threshold:\t\t 0.91\n",
      "\n",
      "***** EARLY STOP *****\n",
      "\n",
      "Nb claims:\t\t 22\n",
      "Average nb annots:\t 7.23\n",
      "Average CI width:\t 0.52\n",
      "Average sample size:\t 29.27\n",
      "Average threshold:\t 0.29\n",
      "Std average threshold:\t 0.09\n",
      "Max threshold:\t\t 0.95\n",
      "Min threshold:\t\t 0.61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report(dep_record, df_dep, traits_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94052c-956a-4963-bcaa-3e3dbc088a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308b812d-f1e9-4aa7-948a-621f7d145eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
