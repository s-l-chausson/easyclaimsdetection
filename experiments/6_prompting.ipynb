{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0bf92-df54-47f9-9d3f-5b7dd03ac45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263476dc-0b5b-43d2-abce-30ad5a7d273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7ae58-e522-4df9-8e93-78558dec9e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0025650-e0b6-451e-95c0-eca4f104d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754035b-65ef-4629-acdf-1f9431197d4a",
   "metadata": {},
   "source": [
    "# Get predictions from Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820552a-7625-40c7-bb92-565c905dedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffeced0-f215-4162-b971-cc1bf5969ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fcd0b5-248d-4d9e-85fb-77fffdb2e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae5807-6699-466e-bab5-b614f0ccf6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a44b96-1cae-4291-a8e6-0bc3c6e19232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LLAMA_pred(text_frmtd, claim, prompt):\n",
    "    prompt_frmt = prompt.format(\n",
    "        TWEET=text_frmtd,\n",
    "        CLAIM=claim,\n",
    "    )\n",
    "\n",
    "    sequences = pipeline(\n",
    "        prompt_frmt,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=1\n",
    "    )\n",
    "\n",
    "    resp = sequences[0]['generated_text'].split()[-1]\n",
    "\n",
    "    return resp\n",
    "\n",
    "def get_llama_2_claim_preds(text, claims_list, prompt):\n",
    "    results = dict()\n",
    "    for claim in claims_list:\n",
    "        results[claim] = get_LLAMA_pred(text, claim, prompt)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892b7dc-9caa-4811-af6a-6818e3fceaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6501059-0531-401e-a89f-41bab11cdea7",
   "metadata": {},
   "source": [
    "## Climate change task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cea092-dbe9-483a-80a8-50712582329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/climate_change/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28d46fe-7231-48fc-a896-dae6f3964c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_list_cc = sorted(list(set([k for l in df[\"FSL_BART\"].to_list() for k in l])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57d93e-c5a6-4c53-a84c-284875ad9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_cc = '''Decide whether the text implies the claim, answering with YES or NO. For example:\n",
    "\n",
    "Text: If you discover Earths temperature has stabilized at a local high since 1998, you can expect it to begin cooling soon. Maybe -15C. Because a new ice age has begun.\n",
    "Claim: We are heading into an ice age\n",
    "Answer: Yes\n",
    "\n",
    "Text: Congress and the next Administration should open access to America's abundant reserves, reduce the regulatory burden, and let states regulate energy production within their borders.\n",
    "Claim: Global warming is not happening\n",
    "Answer: No\n",
    "\n",
    "Text: {TWEET}\n",
    "Claim: {CLAIM}\n",
    "Answer: '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36830646-d837-49e2-9001-b14828c4c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Llama-2\"] = df[\"text\"].apply(lambda x: get_llama_2_claim_preds(x, claims_list_cc, prompt_cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4041c4-f4cd-423d-a54a-a1777d23c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./data/climate_change/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bfa22-ed65-4781-a2f6-a58c7f3b9df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88b709de-66ca-48ac-8b31-cbe77dafb84e",
   "metadata": {},
   "source": [
    "## Topic stance task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af467de-4632-4e4a-a4ee-1c99571e091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/topic_stance/testing.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f5471-a714-42c4-be32-8a20f00b3176",
   "metadata": {},
   "source": [
    "### Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c32494-d507-4f70-b38f-c762b3e818e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_list_t = sorted(list(set(df[\"Target\"].to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b165d02d-870b-4d32-9e84-ac0de5c1fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_t = '''Decide whether the topic relates to the text, answering with YES or NO. For example:\n",
    "\n",
    "Text: SO EXCITING! Meaningful climate change action is on the way!\n",
    "Topic: Climate Change is a Real Concern\n",
    "Answer: Yes\n",
    "\n",
    "Text: Blessed are the peacemakers, for they shall be called children of God. Matthew 5:9\n",
    "Topic: Feminist Movement\n",
    "Answer: No\n",
    "\n",
    "Text: {TWEET}\n",
    "Topic: {CLAIM}\n",
    "Answer: '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930474c-0c6c-4568-9603-c3e2ba0f87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Llama-2\"] = df[\"text\"].apply(lambda x: get_llama_2_claim_preds(x, claims_list_t, prompt_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0189cf4-3867-4df6-b2b1-c1b8b41843d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5dcca04-f039-4aa2-83d0-f0a458df0c47",
   "metadata": {},
   "source": [
    "###Â Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5451fbf-629e-44b6-bc08-ec13efee267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_s = '''Decide whether the topic relates to the text, answering with ANTI, PRO or NEUTRAL. For example:\n",
    "\n",
    "Text: SO EXCITING! Meaningful climate change action is on the way! \n",
    "Topic: Climate Change is a Real Concern\n",
    "Stance: Pro\n",
    "\n",
    "Text: Let's agree that it's not ok to kill a 7lbs baby in the uterus\n",
    "Topic: Legalization of Abortion\n",
    "Stance: Anti\n",
    "\n",
    "Text: {TWEET}\n",
    "Topic: {CLAIM}\n",
    "Stance: '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cff695-84aa-44a5-b59f-4b0151bd6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_2_stance_pred(text, topic_preds):\n",
    "    results = dict()\n",
    "    for claim in topic_preds:\n",
    "    if topic_preds[claim].lower().strip() == \"yes\":\n",
    "        results[claim] = get_LLAMA_pred(text, claim, prompt_4)\n",
    "        print(results[claim])\n",
    "        input()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8d249-ada0-4762-a4e9-6ac618c1e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Llama-2_STANCE\"] = df.apply(lambda x: get_llama_2_stance_pred(x[\"Tweet\"], x[\"Llama-2\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129f0ee-b024-4e84-ba43-5bfa7d0d7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./data/topic_stance/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9ffdc-a069-4b47-8948-3da1efa21057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca8dea9d-e9b1-4602-bd68-61145ba81314",
   "metadata": {},
   "source": [
    "## Depression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4192390-a8b0-43f1-b3fb-4a1a00382e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/depression/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05bc64b-af72-4665-aca8-4d81ac54e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_list_depr = sorted(list(set([k for l in df[\"FSL_BART\"].to_list() for k in l])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a55906-0e03-4164-b567-e695fa4e5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_depr = '''Decide whether the text implies the claim, answering with YES or NO. For example:\n",
    "\n",
    "Text: Everything I used to be passionate about has gone down the drain.\n",
    "Claim: It's hard to get interested in anything\n",
    "Answer: Yes\n",
    "\n",
    "Text: I cry and care too much, which leaves me burnt out and exhausted.\n",
    "Claim: I dislike myself\n",
    "Answer: No\n",
    "\n",
    "Text: {TWEET}\n",
    "Claim: {CLAIM}\n",
    "Answer: '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598bce95-4e40-4992-b51d-03410e665154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Llama-2\"] = df[\"Sentence\"].apply(lambda x: get_llama_2_claim_preds(x, claims_list_depr, prompt_depr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382de13-4210-4fce-8c8c-1a11ea50c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./data/depression/testing.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b474288-d92b-47ac-a2bb-4ee15a6ac526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2343ed9-0ef9-4d08-8d00-a3ee0baa1651",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
